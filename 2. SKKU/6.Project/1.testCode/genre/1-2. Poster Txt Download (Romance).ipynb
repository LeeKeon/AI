{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "import pandas as pd\n",
    "import os\n",
    "label_path = \"./dataset/MovieGenre_fix_leekeon_total6000.csv\"\n",
    "movie_df = pd.read_csv(label_path, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4188654\n",
      "5566660\n"
     ]
    }
   ],
   "source": [
    "for movie in movie_df.values:\n",
    "    #print(movie[3]) #link\n",
    "    #print(movie[6]) #genre\n",
    "    #print(movie[1]) #id\n",
    "    \n",
    "    # movie[0] ID\n",
    "    # movie[7] Genre\n",
    "    # movie[8] Image link \n",
    "    try:\n",
    "        if(movie[7]=='Romance'):\n",
    "            url = str(movie[3]) + '/plotsummary?ref_=tt_ov_pl'\n",
    "            res = req.urlopen(url)\n",
    "            soup = BeautifulSoup(res, \"html.parser\")   \n",
    "            synop = soup.find('li', 'ipl-zebra-list__item')\n",
    "            synop = synop.find('p')\n",
    "            synop = str(synop).replace('</p>', '')\n",
    "            synop = synop.replace('<p>', '')\n",
    "    \n",
    "            save_path = './dataset/poster_txt/new/Romance/' + str(movie[1]) + '.txt'\n",
    "            file = open(save_path,'w')\n",
    "            file.write(synop)\n",
    "            file.flush()\n",
    "    except:\n",
    "        print(movie[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "label_path = \"./dataset/MovieGenre_genre500_final.csv\"\n",
    "movie_df = pd.read_csv(label_path, encoding=\"ISO-8859-1\")\n",
    "\n",
    "file = open('./dataset/poster_txt/Western/test.txt','w')\n",
    "file.write(\"Hello World\")\n",
    "file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "####################################\n",
    "# The Music Lyrics Database\n",
    "####################################\n",
    "site_url = \"http://www.mldb.org/\"\n",
    "\n",
    "song_list = []\n",
    "total_cnt = 0\n",
    "cnt = 0\n",
    "\n",
    "###############################################\n",
    "# start function\n",
    "###############################################\n",
    "def get_all_songs(artist):\n",
    "    global song_list\n",
    "    global cnt\n",
    "    \n",
    "    song_list = []\n",
    "    cnt = 0\n",
    "    \n",
    "    if len(artist) == 0:\n",
    "        return\n",
    "    \n",
    "    artist = artist.strip().lower()\n",
    "    \n",
    "    get_search_list(artist)\n",
    "    \n",
    "    print('# ', artist, \" : \", cnt)\n",
    "        \n",
    "    return\n",
    "\n",
    "###############################################\n",
    "# 1st page song list and other search page list\n",
    "###############################################\n",
    "def get_search_list(artist):\n",
    "    url = site_url + \"search?si=1&mm=2&ob=1&mq=\" + artist.replace(' ', '+')\n",
    "    \n",
    "    # print('url : ' , url)\n",
    "    res = req.urlopen(url)\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    links = soup.find_all(\"a\")\n",
    "    b4txt = \"\"\n",
    "\n",
    "    for a in links:\n",
    "        href = a.attrs['href']\n",
    "        text = a.string.lower()\n",
    "        \n",
    "        if b4txt.find(artist) >= 0 and href.startswith('song'):\n",
    "            # print(text , \" > \", href)\n",
    "            get_song_lyrics(artist, text, href)\n",
    "        elif href.startswith('search'):\n",
    "            # print(text , \" : \", href)\n",
    "            get_song_list(artist, href)\n",
    "        else:\n",
    "            b4txt = text\n",
    "            # print(text , \" = \", href)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################\n",
    "# after 1st page song list, from 2nd page\n",
    "##########################################\n",
    "def get_song_list(artist, param):\n",
    "    url = site_url + param\n",
    "    \n",
    "    # print('url : ' , url)\n",
    "    res = req.urlopen(url)\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    links = soup.find_all(\"a\")\n",
    "    b4txt = \"\"\n",
    "  \n",
    "    for a in links:\n",
    "        href = a.attrs['href']\n",
    "        text = a.string.lower()\n",
    "        \n",
    "        if b4txt.find(artist) >= 0 and href.startswith('song'):\n",
    "            # print(text , \" > \", href)\n",
    "            get_song_lyrics(artist, text, href)\n",
    "        else:\n",
    "            b4txt = text\n",
    "            \n",
    "    return\n",
    "\n",
    "####################################\n",
    "# get each song lyrics to write file\n",
    "####################################\n",
    "def get_song_lyrics(artist, title, param):\n",
    "    \n",
    "    global song_list\n",
    "    global max_cnt, cnt, total_cnt\n",
    "    \n",
    "    if cnt >= 50:\n",
    "        print('# max ', total_cnt, \" \", cnt)\n",
    "        return    \n",
    "    \n",
    "    pos = title.find('(')\n",
    "    if (pos > 0): title = title[:pos].strip()\n",
    "    \n",
    "    if title in song_list:\n",
    "        print('# already get : ', title)\n",
    "        return\n",
    "    \n",
    "    song_list.append(title)\n",
    "    \n",
    "    url = site_url + param\n",
    "    # print('# ', total_cnt, \" \", cnt, \" \", artist , ' : ', title, ' : ' , url)\n",
    "        \n",
    "    res = req.urlopen(url)\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    \n",
    "    p_str = str(soup.find('p'))\n",
    "    p_str = p_str[(p_str.find('>')+1):]\n",
    "    p_str = p_str.replace('<br/>', ' ')\n",
    "    p_str = p_str.replace('</p>', '')\n",
    "    \n",
    "    # print(p_str)\n",
    "    \n",
    "    file_name = 'lyrics/' + artist + '_' +title + '.txt'\n",
    "    print('# file : ', cnt, ' ', file_name)\n",
    "    \n",
    "    try:\n",
    "        with open(file_name, 'w', encoding='utf8') as f:\n",
    "            f.write(str(p_str))\n",
    "            cnt = cnt+1\n",
    "    except OSError as err:\n",
    "        print(\"OS error: {0}\".format(err))\n",
    "    \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
