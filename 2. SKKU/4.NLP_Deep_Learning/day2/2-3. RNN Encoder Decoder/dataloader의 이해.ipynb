{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "max_len = 40\n",
    "\n",
    "w2idx ={'<eos>': 777777}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def file_to_ids(file_name):\n",
    "        with open(file_name, \"r\") as fin:\n",
    "            lines = fin.readlines()\n",
    "\n",
    "        length, ids = [], []\n",
    "        for num, line in enumerate(lines):\n",
    "            id = np.zeros(max_len, dtype=np.int32)\n",
    "            line += \" <eos>\"\n",
    "            words = line.split()\n",
    "            for i, word in enumerate(words):\n",
    "                if i == max_len:\n",
    "                    break\n",
    "                if word not in w2idx:\n",
    "                    w2idx[word] = len(w2idx)\n",
    "                id[i] = w2idx[word]\n",
    "            ids.append(id)\n",
    "            length.append(i)\n",
    "\n",
    "            if num == 100000:\n",
    "                break\n",
    "\n",
    "        return np.array(ids), np.array(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/ptb/ptb.train.txt'\n",
    "\n",
    "ids, length = file_to_ids(path)\n",
    "\n",
    "#기존의 dataload와 같은데 sentence의 길이를 40으로 고정하도록 0으로 채우고 sentence의 끝을 지정함\n",
    "#length는 기존대로 sentence의 길이를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42068, 15)\n",
      "[[   1    2    3 ...   13   14   15]\n",
      " [  25   26   27 ...   37   38   27]\n",
      " [  39   26   40 ...    0    0    0]\n",
      " ...\n",
      " [4399 5019   35 ... 9999  119  857]\n",
      " [  78  835   30 ...    0    0    0]\n",
      " [ 108 3622 3623 ...  704 9999  119]]\n"
     ]
    }
   ],
   "source": [
    "x_input_batch = ids[:,:15]\n",
    "print(x_input_batch.shape)\n",
    "print(x_input_batch)\n",
    "#target_labels = self.decoder_output[:, :self.batch_max_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class text_data(object):\n",
    "    def __init__(self, path=\"./dataset/ptb\", max_len=40, end_token=\"<eos>\"):\n",
    "        self.train_pt, self.val_pt, self.test_pt = 0, 0, 0\n",
    "        self.path = path\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.w2idx ={end_token: 0}\n",
    "        self.train_ids, self.train_len = self.file_to_ids(path+\"/ptb.train.txt\")\n",
    "        self.val_ids, self.val_len = self.file_to_ids(path + \"/ptb.train.txt\")\n",
    "        self.test_ids, self.test_len = self.file_to_ids(path + \"/ptb.train.txt\")\n",
    "        self.vocab_size = len(self.w2idx)\n",
    "\n",
    "        self.train_size = len(self.train_ids)\n",
    "        self.val_size = len(self.val_ids)\n",
    "        self.test_size = len(self.test_ids)\n",
    "\n",
    "        self.idx2w = {}\n",
    "        for word in self.w2idx:\n",
    "            self.idx2w[self.w2idx[word]] = word\n",
    "\n",
    "    def file_to_ids(self, file_name):\n",
    "        with open(file_name, \"r\") as fin:\n",
    "            lines = fin.readlines()\n",
    "\n",
    "        length, ids = [], []\n",
    "        for num, line in enumerate(lines):\n",
    "            id = np.zeros(self.max_len, dtype=np.int32)\n",
    "            line += \" <eos>\"\n",
    "            words = line.split()\n",
    "            for i, word in enumerate(words):\n",
    "                if i == self.max_len:\n",
    "                    break\n",
    "                if word not in self.w2idx:\n",
    "                    self.w2idx[word] = len(self.w2idx)\n",
    "                id[i] = self.w2idx[word]\n",
    "            ids.append(id)\n",
    "            length.append(i)\n",
    "\n",
    "            if num == 100000:\n",
    "                break\n",
    "\n",
    "        return np.array(ids), np.array(length)\n",
    "\n",
    "    def get_train(self, batch_size=20):\n",
    "        pt = self.train_pt\n",
    "        self.train_pt = (self.train_pt + batch_size) % self.train_size\n",
    "        return self.train_ids[pt: pt+batch_size], self.train_len[pt: pt+batch_size]\n",
    "\n",
    "    def get_val(self, batch_size=20):\n",
    "        pt = self.val_pt\n",
    "        self.val_pt = (self.val_pt + batch_size) % self.val_size\n",
    "        return self.val_ids[pt: pt+batch_size], self.val_len[pt: pt+batch_size]\n",
    "\n",
    "    def get_test(self, batch_size=20):\n",
    "        pt = self.test_pt\n",
    "        self.test_pt = (self.test_pt + batch_size) % self.test_size\n",
    "        return self.test_ids[pt: pt+batch_size], self.test_len[pt: pt+batch_size]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
