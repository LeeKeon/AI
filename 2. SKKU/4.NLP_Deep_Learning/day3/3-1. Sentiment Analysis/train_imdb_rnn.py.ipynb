{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it:   10 | loss: 0.692 | acc: 0.530 - 2.97s\n",
      " it:   20 | loss: 0.698 | acc: 0.610 - 5.21s\n",
      " it:   30 | loss: 0.703 | acc: 0.470 - 7.35s\n",
      " it:   40 | loss: 0.692 | acc: 0.520 - 9.44s\n",
      " it:   50 | loss: 0.692 | acc: 0.520 - 11.56s\n",
      " it:   60 | loss: 0.689 | acc: 0.560 - 13.60s\n",
      " it:   70 | loss: 0.677 | acc: 0.650 - 15.85s\n",
      " it:   80 | loss: 0.713 | acc: 0.520 - 18.28s\n",
      " it:   90 | loss: 0.688 | acc: 0.500 - 20.46s\n",
      " it:  100 | loss: 0.682 | acc: 0.590 - 22.60s\n",
      " --> test_loss: 0.611 | test_acc: 0.700\n",
      " it:  110 | loss: 0.736 | acc: 0.570 - 33.04s\n",
      " it:  120 | loss: 0.689 | acc: 0.530 - 35.44s\n",
      " it:  130 | loss: 0.704 | acc: 0.450 - 37.80s\n",
      " it:  140 | loss: 0.668 | acc: 0.550 - 40.04s\n",
      " it:  150 | loss: 0.695 | acc: 0.550 - 42.56s\n",
      " it:  160 | loss: 0.681 | acc: 0.570 - 44.82s\n",
      " it:  170 | loss: 0.678 | acc: 0.560 - 47.05s\n",
      " it:  180 | loss: 0.719 | acc: 0.650 - 49.48s\n",
      " it:  190 | loss: 0.707 | acc: 0.520 - 51.73s\n",
      " it:  200 | loss: 0.702 | acc: 0.520 - 54.12s\n",
      " --> test_loss: 0.685 | test_acc: 0.600\n",
      " it:  210 | loss: 0.670 | acc: 0.610 - 65.03s\n",
      " it:  220 | loss: 0.673 | acc: 0.540 - 67.32s\n",
      " it:  230 | loss: 0.666 | acc: 0.630 - 69.59s\n",
      " it:  240 | loss: 0.621 | acc: 0.630 - 71.86s\n",
      " it:  250 | loss: 0.684 | acc: 0.570 - 74.08s\n",
      " it:  260 | loss: 0.688 | acc: 0.560 - 76.27s\n",
      " it:  270 | loss: 0.646 | acc: 0.660 - 78.78s\n",
      " it:  280 | loss: 0.669 | acc: 0.610 - 81.12s\n",
      " it:  290 | loss: 0.654 | acc: 0.590 - 83.49s\n",
      " it:  300 | loss: 0.619 | acc: 0.670 - 85.79s\n",
      " --> test_loss: 0.646 | test_acc: 0.600\n",
      " it:  310 | loss: 0.572 | acc: 0.710 - 96.57s\n",
      " it:  320 | loss: 0.583 | acc: 0.700 - 98.84s\n",
      " it:  330 | loss: 0.648 | acc: 0.670 - 101.17s\n",
      " it:  340 | loss: 0.674 | acc: 0.610 - 103.47s\n",
      " it:  350 | loss: 0.666 | acc: 0.600 - 105.79s\n",
      " it:  360 | loss: 0.612 | acc: 0.660 - 108.14s\n",
      " it:  370 | loss: 0.658 | acc: 0.620 - 110.70s\n",
      " it:  380 | loss: 0.608 | acc: 0.660 - 113.22s\n",
      " it:  390 | loss: 0.665 | acc: 0.650 - 115.44s\n",
      " it:  400 | loss: 0.691 | acc: 0.580 - 117.84s\n",
      " --> test_loss: 0.643 | test_acc: 0.400\n",
      " it:  410 | loss: 0.651 | acc: 0.610 - 128.97s\n",
      " it:  420 | loss: 0.630 | acc: 0.700 - 131.31s\n",
      " it:  430 | loss: 0.636 | acc: 0.670 - 133.77s\n",
      " it:  440 | loss: 0.563 | acc: 0.730 - 136.10s\n",
      " it:  450 | loss: 0.576 | acc: 0.700 - 138.66s\n",
      " it:  460 | loss: 0.678 | acc: 0.530 - 141.07s\n",
      " it:  470 | loss: 0.584 | acc: 0.680 - 143.33s\n",
      " it:  480 | loss: 0.658 | acc: 0.590 - 145.71s\n",
      " it:  490 | loss: 0.600 | acc: 0.710 - 148.01s\n",
      " it:  500 | loss: 0.668 | acc: 0.620 - 150.30s\n",
      " --> test_loss: 0.628 | test_acc: 0.800\n",
      " it:  510 | loss: 0.642 | acc: 0.630 - 161.46s\n",
      " it:  520 | loss: 0.632 | acc: 0.630 - 163.77s\n",
      " it:  530 | loss: 0.593 | acc: 0.700 - 166.32s\n",
      " it:  540 | loss: 0.480 | acc: 0.750 - 168.87s\n",
      " it:  550 | loss: 0.766 | acc: 0.620 - 171.30s\n",
      " it:  560 | loss: 0.704 | acc: 0.580 - 173.62s\n",
      " it:  570 | loss: 0.665 | acc: 0.580 - 176.15s\n",
      " it:  580 | loss: 0.606 | acc: 0.640 - 178.52s\n",
      " it:  590 | loss: 0.553 | acc: 0.740 - 180.84s\n",
      " it:  600 | loss: 0.603 | acc: 0.680 - 183.16s\n",
      " --> test_loss: 0.664 | test_acc: 0.500\n",
      " it:  610 | loss: 0.629 | acc: 0.700 - 194.35s\n",
      " it:  620 | loss: 0.513 | acc: 0.780 - 196.70s\n",
      " it:  630 | loss: 0.556 | acc: 0.720 - 199.13s\n",
      " it:  640 | loss: 0.602 | acc: 0.660 - 201.44s\n",
      " it:  650 | loss: 0.499 | acc: 0.770 - 203.64s\n",
      " it:  660 | loss: 0.419 | acc: 0.820 - 205.96s\n",
      " it:  670 | loss: 0.517 | acc: 0.770 - 208.44s\n",
      " it:  680 | loss: 0.576 | acc: 0.720 - 210.71s\n",
      " it:  690 | loss: 0.609 | acc: 0.700 - 213.05s\n",
      " it:  700 | loss: 0.497 | acc: 0.770 - 215.60s\n",
      " --> test_loss: 0.526 | test_acc: 0.800\n",
      " it:  710 | loss: 0.513 | acc: 0.780 - 226.71s\n",
      " it:  720 | loss: 0.456 | acc: 0.780 - 229.06s\n",
      " it:  730 | loss: 0.491 | acc: 0.790 - 231.53s\n",
      " it:  740 | loss: 0.580 | acc: 0.700 - 234.02s\n",
      " it:  750 | loss: 0.599 | acc: 0.660 - 236.52s\n",
      " it:  760 | loss: 0.576 | acc: 0.670 - 238.95s\n",
      " it:  770 | loss: 0.505 | acc: 0.720 - 241.59s\n",
      " it:  780 | loss: 0.459 | acc: 0.790 - 243.99s\n",
      " it:  790 | loss: 0.526 | acc: 0.730 - 246.34s\n",
      " it:  800 | loss: 0.539 | acc: 0.690 - 248.65s\n",
      " --> test_loss: 0.496 | test_acc: 0.700\n",
      " it:  810 | loss: 0.564 | acc: 0.730 - 259.73s\n",
      " it:  820 | loss: 0.472 | acc: 0.790 - 262.26s\n",
      " it:  830 | loss: 0.550 | acc: 0.740 - 264.62s\n",
      " it:  840 | loss: 0.549 | acc: 0.740 - 266.92s\n",
      " it:  850 | loss: 0.479 | acc: 0.800 - 269.34s\n",
      " it:  860 | loss: 0.553 | acc: 0.720 - 271.63s\n",
      " it:  870 | loss: 0.538 | acc: 0.780 - 274.13s\n",
      " it:  880 | loss: 0.431 | acc: 0.820 - 276.64s\n",
      " it:  890 | loss: 0.475 | acc: 0.760 - 279.30s\n",
      " it:  900 | loss: 0.382 | acc: 0.850 - 281.84s\n",
      " --> test_loss: 0.450 | test_acc: 1.000\n",
      " it:  910 | loss: 0.557 | acc: 0.730 - 292.89s\n",
      " it:  920 | loss: 0.455 | acc: 0.780 - 295.21s\n",
      " it:  930 | loss: 0.462 | acc: 0.760 - 297.57s\n",
      " it:  940 | loss: 0.590 | acc: 0.710 - 300.02s\n",
      " it:  950 | loss: 0.548 | acc: 0.750 - 302.49s\n",
      " it:  960 | loss: 0.442 | acc: 0.760 - 305.10s\n",
      " it:  970 | loss: 0.501 | acc: 0.750 - 307.56s\n",
      " it:  980 | loss: 0.440 | acc: 0.790 - 309.94s\n",
      " it:  990 | loss: 0.358 | acc: 0.850 - 312.62s\n",
      " it: 1000 | loss: 0.385 | acc: 0.840 - 315.33s\n",
      " --> test_loss: 0.444 | test_acc: 0.700\n",
      "WARNING:tensorflow:From /home/frank/github_KeonLee/AI/2. SKKU/4.NLP_Deep_Learning/day3/3-1. Sentiment Analysis/rnn_model.py:75: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      " * model saved at 'models/cnn'\n",
      " it: 1010 | loss: 0.455 | acc: 0.820 - 328.07s\n",
      " it: 1020 | loss: 0.476 | acc: 0.810 - 330.42s\n",
      " it: 1030 | loss: 0.375 | acc: 0.840 - 332.84s\n",
      " it: 1040 | loss: 0.390 | acc: 0.840 - 335.59s\n",
      " it: 1050 | loss: 0.453 | acc: 0.820 - 338.07s\n",
      " it: 1060 | loss: 0.532 | acc: 0.730 - 340.43s\n",
      " it: 1070 | loss: 0.462 | acc: 0.770 - 342.86s\n",
      " it: 1080 | loss: 0.485 | acc: 0.790 - 345.06s\n",
      " it: 1090 | loss: 0.413 | acc: 0.840 - 347.62s\n",
      " it: 1100 | loss: 0.314 | acc: 0.880 - 350.48s\n",
      " --> test_loss: 0.436 | test_acc: 0.700\n",
      " it: 1110 | loss: 0.402 | acc: 0.780 - 362.14s\n",
      " it: 1120 | loss: 0.454 | acc: 0.800 - 364.50s\n",
      " it: 1130 | loss: 0.379 | acc: 0.820 - 366.90s\n",
      " it: 1140 | loss: 0.378 | acc: 0.830 - 369.33s\n",
      " it: 1150 | loss: 0.243 | acc: 0.910 - 371.69s\n",
      " it: 1160 | loss: 0.290 | acc: 0.860 - 373.93s\n",
      " it: 1170 | loss: 0.627 | acc: 0.760 - 376.17s\n",
      " it: 1180 | loss: 0.477 | acc: 0.770 - 378.75s\n",
      " it: 1190 | loss: 0.395 | acc: 0.800 - 381.52s\n",
      " it: 1200 | loss: 0.381 | acc: 0.870 - 383.86s\n",
      " --> test_loss: 0.449 | test_acc: 0.900\n",
      " it: 1210 | loss: 0.352 | acc: 0.840 - 394.96s\n",
      " it: 1220 | loss: 0.470 | acc: 0.830 - 397.29s\n",
      " it: 1230 | loss: 0.397 | acc: 0.820 - 399.73s\n",
      " it: 1240 | loss: 0.366 | acc: 0.860 - 402.03s\n",
      " it: 1250 | loss: 0.388 | acc: 0.840 - 404.42s\n",
      " it: 1260 | loss: 0.356 | acc: 0.850 - 406.87s\n",
      " it: 1270 | loss: 0.424 | acc: 0.810 - 409.47s\n",
      " it: 1280 | loss: 0.342 | acc: 0.830 - 412.43s\n",
      " it: 1290 | loss: 0.368 | acc: 0.860 - 414.77s\n",
      " it: 1300 | loss: 0.345 | acc: 0.840 - 416.95s\n",
      " --> test_loss: 0.398 | test_acc: 1.000\n",
      " it: 1310 | loss: 0.287 | acc: 0.870 - 429.16s\n",
      " it: 1320 | loss: 0.394 | acc: 0.810 - 432.05s\n",
      " it: 1330 | loss: 0.388 | acc: 0.850 - 434.40s\n",
      " it: 1340 | loss: 0.502 | acc: 0.770 - 436.62s\n",
      " it: 1350 | loss: 0.366 | acc: 0.850 - 439.18s\n",
      " it: 1360 | loss: 0.395 | acc: 0.790 - 441.65s\n",
      " it: 1370 | loss: 0.354 | acc: 0.880 - 443.84s\n",
      " it: 1380 | loss: 0.445 | acc: 0.790 - 446.11s\n",
      " it: 1390 | loss: 0.350 | acc: 0.840 - 448.29s\n",
      " it: 1400 | loss: 0.312 | acc: 0.900 - 450.50s\n",
      " --> test_loss: 0.395 | test_acc: 1.000\n",
      " it: 1410 | loss: 0.414 | acc: 0.840 - 461.44s\n",
      " it: 1420 | loss: 0.366 | acc: 0.870 - 463.57s\n",
      " it: 1430 | loss: 0.336 | acc: 0.890 - 465.76s\n",
      " it: 1440 | loss: 0.296 | acc: 0.900 - 468.08s\n",
      " it: 1450 | loss: 0.256 | acc: 0.890 - 470.31s\n",
      " it: 1460 | loss: 0.359 | acc: 0.840 - 472.48s\n",
      " it: 1470 | loss: 0.359 | acc: 0.850 - 474.90s\n",
      " it: 1480 | loss: 0.239 | acc: 0.900 - 477.25s\n",
      " it: 1490 | loss: 0.365 | acc: 0.840 - 479.51s\n",
      " it: 1500 | loss: 0.366 | acc: 0.860 - 481.87s\n",
      " --> test_loss: 0.406 | test_acc: 0.800\n",
      " it: 1510 | loss: 0.360 | acc: 0.870 - 492.78s\n",
      " it: 1520 | loss: 0.383 | acc: 0.810 - 495.15s\n",
      " it: 1530 | loss: 0.363 | acc: 0.820 - 497.49s\n",
      " it: 1540 | loss: 0.341 | acc: 0.830 - 499.80s\n",
      " it: 1550 | loss: 0.413 | acc: 0.840 - 502.16s\n",
      " it: 1560 | loss: 0.362 | acc: 0.860 - 504.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it: 1570 | loss: 0.397 | acc: 0.810 - 506.91s\n",
      " it: 1580 | loss: 0.383 | acc: 0.850 - 509.39s\n",
      " it: 1590 | loss: 0.304 | acc: 0.870 - 511.63s\n",
      " it: 1600 | loss: 0.309 | acc: 0.860 - 514.16s\n",
      " --> test_loss: 0.343 | test_acc: 0.800\n",
      " it: 1610 | loss: 0.318 | acc: 0.870 - 528.07s\n",
      " it: 1620 | loss: 0.334 | acc: 0.840 - 531.00s\n",
      " it: 1630 | loss: 0.265 | acc: 0.900 - 533.85s\n",
      " it: 1640 | loss: 0.308 | acc: 0.890 - 536.91s\n",
      " it: 1650 | loss: 0.395 | acc: 0.860 - 539.38s\n",
      " it: 1660 | loss: 0.325 | acc: 0.870 - 541.50s\n",
      " it: 1670 | loss: 0.362 | acc: 0.840 - 543.74s\n",
      " it: 1680 | loss: 0.371 | acc: 0.850 - 545.92s\n",
      " it: 1690 | loss: 0.313 | acc: 0.840 - 548.76s\n",
      " it: 1700 | loss: 0.343 | acc: 0.850 - 551.68s\n",
      " --> test_loss: 0.322 | test_acc: 1.000\n",
      " it: 1710 | loss: 0.340 | acc: 0.850 - 565.54s\n",
      " it: 1720 | loss: 0.347 | acc: 0.840 - 567.94s\n",
      " it: 1730 | loss: 0.433 | acc: 0.780 - 570.49s\n",
      " it: 1740 | loss: 0.346 | acc: 0.830 - 572.73s\n",
      " it: 1750 | loss: 0.302 | acc: 0.890 - 574.95s\n",
      " it: 1760 | loss: 0.367 | acc: 0.810 - 577.18s\n",
      " it: 1770 | loss: 0.303 | acc: 0.870 - 579.37s\n",
      " it: 1780 | loss: 0.314 | acc: 0.890 - 581.94s\n",
      " it: 1790 | loss: 0.263 | acc: 0.890 - 585.07s\n",
      " it: 1800 | loss: 0.188 | acc: 0.930 - 587.34s\n",
      " --> test_loss: 0.347 | test_acc: 1.000\n",
      " it: 1810 | loss: 0.290 | acc: 0.870 - 598.75s\n",
      " it: 1820 | loss: 0.313 | acc: 0.860 - 602.07s\n",
      " it: 1830 | loss: 0.444 | acc: 0.840 - 605.20s\n",
      " it: 1840 | loss: 0.315 | acc: 0.850 - 607.71s\n",
      " it: 1850 | loss: 0.368 | acc: 0.860 - 609.99s\n",
      " it: 1860 | loss: 0.399 | acc: 0.820 - 613.04s\n",
      " it: 1870 | loss: 0.370 | acc: 0.840 - 617.29s\n",
      " it: 1880 | loss: 0.371 | acc: 0.820 - 620.02s\n",
      " it: 1890 | loss: 0.365 | acc: 0.840 - 622.53s\n",
      " it: 1900 | loss: 0.328 | acc: 0.890 - 624.96s\n",
      " --> test_loss: 0.340 | test_acc: 0.900\n",
      " it: 1910 | loss: 0.254 | acc: 0.900 - 636.68s\n",
      " it: 1920 | loss: 0.432 | acc: 0.830 - 638.84s\n",
      " it: 1930 | loss: 0.282 | acc: 0.900 - 641.13s\n",
      " it: 1940 | loss: 0.244 | acc: 0.880 - 643.48s\n",
      " it: 1950 | loss: 0.400 | acc: 0.830 - 645.79s\n",
      " it: 1960 | loss: 0.358 | acc: 0.810 - 647.97s\n",
      " it: 1970 | loss: 0.239 | acc: 0.900 - 650.20s\n",
      " it: 1980 | loss: 0.378 | acc: 0.830 - 652.61s\n",
      " it: 1990 | loss: 0.340 | acc: 0.860 - 654.75s\n",
      " it: 2000 | loss: 0.361 | acc: 0.820 - 657.23s\n",
      " --> test_loss: 0.336 | test_acc: 0.800\n",
      " * model saved at 'models/cnn'\n",
      " it: 2010 | loss: 0.231 | acc: 0.890 - 670.16s\n",
      " it: 2020 | loss: 0.232 | acc: 0.880 - 672.65s\n",
      " it: 2030 | loss: 0.459 | acc: 0.820 - 675.58s\n",
      " it: 2040 | loss: 0.272 | acc: 0.890 - 678.54s\n",
      " it: 2050 | loss: 0.364 | acc: 0.860 - 680.84s\n",
      " it: 2060 | loss: 0.314 | acc: 0.850 - 683.15s\n",
      " it: 2070 | loss: 0.306 | acc: 0.870 - 685.28s\n",
      " it: 2080 | loss: 0.324 | acc: 0.880 - 687.97s\n",
      " it: 2090 | loss: 0.317 | acc: 0.860 - 690.86s\n",
      " it: 2100 | loss: 0.233 | acc: 0.900 - 693.02s\n",
      " --> test_loss: 0.355 | test_acc: 1.000\n",
      " it: 2110 | loss: 0.325 | acc: 0.850 - 704.12s\n",
      " it: 2120 | loss: 0.274 | acc: 0.890 - 707.09s\n",
      " it: 2130 | loss: 0.393 | acc: 0.840 - 709.77s\n",
      " it: 2140 | loss: 0.308 | acc: 0.860 - 712.00s\n",
      " it: 2150 | loss: 0.436 | acc: 0.810 - 714.23s\n",
      " it: 2160 | loss: 0.446 | acc: 0.840 - 716.76s\n",
      " it: 2170 | loss: 0.339 | acc: 0.800 - 719.72s\n",
      " it: 2180 | loss: 0.422 | acc: 0.800 - 721.91s\n",
      " it: 2190 | loss: 0.281 | acc: 0.870 - 724.29s\n",
      " it: 2200 | loss: 0.288 | acc: 0.880 - 726.70s\n",
      " --> test_loss: 0.374 | test_acc: 1.000\n",
      " it: 2210 | loss: 0.279 | acc: 0.890 - 738.81s\n",
      " it: 2220 | loss: 0.262 | acc: 0.880 - 741.36s\n",
      " it: 2230 | loss: 0.429 | acc: 0.810 - 743.65s\n",
      " it: 2240 | loss: 0.253 | acc: 0.900 - 746.13s\n",
      " it: 2250 | loss: 0.304 | acc: 0.880 - 748.76s\n",
      " it: 2260 | loss: 0.253 | acc: 0.930 - 751.35s\n",
      " it: 2270 | loss: 0.323 | acc: 0.880 - 753.57s\n",
      " it: 2280 | loss: 0.342 | acc: 0.870 - 755.74s\n",
      " it: 2290 | loss: 0.439 | acc: 0.840 - 758.16s\n",
      " it: 2300 | loss: 0.313 | acc: 0.840 - 760.40s\n",
      " --> test_loss: 0.366 | test_acc: 1.000\n",
      " it: 2310 | loss: 0.343 | acc: 0.820 - 770.91s\n",
      " it: 2320 | loss: 0.305 | acc: 0.860 - 773.33s\n",
      " it: 2330 | loss: 0.339 | acc: 0.870 - 775.69s\n",
      " it: 2340 | loss: 0.323 | acc: 0.810 - 778.29s\n",
      " it: 2350 | loss: 0.366 | acc: 0.830 - 780.50s\n",
      " it: 2360 | loss: 0.363 | acc: 0.830 - 782.76s\n",
      " it: 2370 | loss: 0.246 | acc: 0.880 - 785.12s\n",
      " it: 2380 | loss: 0.431 | acc: 0.820 - 787.41s\n",
      " it: 2390 | loss: 0.285 | acc: 0.880 - 789.69s\n",
      " it: 2400 | loss: 0.283 | acc: 0.860 - 791.98s\n",
      " --> test_loss: 0.316 | test_acc: 0.900\n",
      " it: 2410 | loss: 0.331 | acc: 0.830 - 802.37s\n",
      " it: 2420 | loss: 0.246 | acc: 0.870 - 804.77s\n",
      " it: 2430 | loss: 0.215 | acc: 0.920 - 807.19s\n",
      " it: 2440 | loss: 0.303 | acc: 0.880 - 809.66s\n",
      " it: 2450 | loss: 0.271 | acc: 0.890 - 811.97s\n",
      " it: 2460 | loss: 0.266 | acc: 0.890 - 814.17s\n",
      " it: 2470 | loss: 0.280 | acc: 0.860 - 816.55s\n",
      " it: 2480 | loss: 0.260 | acc: 0.900 - 818.89s\n",
      " it: 2490 | loss: 0.358 | acc: 0.880 - 821.33s\n",
      " it: 2500 | loss: 0.238 | acc: 0.900 - 823.70s\n",
      " --> test_loss: 0.363 | test_acc: 0.900\n",
      " it: 2510 | loss: 0.300 | acc: 0.890 - 834.20s\n",
      " it: 2520 | loss: 0.317 | acc: 0.890 - 836.71s\n",
      " it: 2530 | loss: 0.367 | acc: 0.850 - 839.75s\n",
      " it: 2540 | loss: 0.247 | acc: 0.880 - 842.89s\n",
      " it: 2550 | loss: 0.275 | acc: 0.890 - 845.80s\n",
      " it: 2560 | loss: 0.358 | acc: 0.820 - 848.69s\n",
      " it: 2570 | loss: 0.233 | acc: 0.900 - 851.61s\n",
      " it: 2580 | loss: 0.200 | acc: 0.930 - 854.43s\n",
      " it: 2590 | loss: 0.301 | acc: 0.870 - 857.23s\n",
      " it: 2600 | loss: 0.211 | acc: 0.920 - 859.67s\n",
      " --> test_loss: 0.305 | test_acc: 1.000\n",
      " it: 2610 | loss: 0.242 | acc: 0.920 - 870.69s\n",
      " it: 2620 | loss: 0.240 | acc: 0.900 - 873.80s\n",
      " it: 2630 | loss: 0.277 | acc: 0.880 - 876.90s\n",
      " it: 2640 | loss: 0.142 | acc: 0.960 - 879.82s\n",
      " it: 2650 | loss: 0.286 | acc: 0.880 - 882.89s\n",
      " it: 2660 | loss: 0.198 | acc: 0.940 - 885.86s\n",
      " it: 2670 | loss: 0.127 | acc: 0.960 - 888.48s\n",
      " it: 2680 | loss: 0.160 | acc: 0.930 - 890.68s\n",
      " it: 2690 | loss: 0.237 | acc: 0.910 - 893.04s\n",
      " it: 2700 | loss: 0.215 | acc: 0.920 - 895.21s\n",
      " --> test_loss: 0.394 | test_acc: 1.000\n",
      " it: 2710 | loss: 0.226 | acc: 0.880 - 905.83s\n",
      " it: 2720 | loss: 0.188 | acc: 0.920 - 907.99s\n",
      " it: 2730 | loss: 0.200 | acc: 0.910 - 910.48s\n",
      " it: 2740 | loss: 0.090 | acc: 0.970 - 912.64s\n",
      " it: 2750 | loss: 0.319 | acc: 0.880 - 914.96s\n",
      " it: 2760 | loss: 0.231 | acc: 0.910 - 917.48s\n",
      " it: 2770 | loss: 0.186 | acc: 0.910 - 919.65s\n",
      " it: 2780 | loss: 0.224 | acc: 0.890 - 921.82s\n",
      " it: 2790 | loss: 0.166 | acc: 0.950 - 923.97s\n",
      " it: 2800 | loss: 0.151 | acc: 0.950 - 926.16s\n",
      " --> test_loss: 0.484 | test_acc: 0.900\n",
      " it: 2810 | loss: 0.115 | acc: 0.960 - 936.71s\n",
      " it: 2820 | loss: 0.098 | acc: 0.960 - 938.95s\n",
      " it: 2830 | loss: 0.166 | acc: 0.930 - 941.30s\n",
      " it: 2840 | loss: 0.151 | acc: 0.930 - 943.43s\n",
      " it: 2850 | loss: 0.142 | acc: 0.940 - 945.85s\n",
      " it: 2860 | loss: 0.115 | acc: 0.950 - 948.19s\n",
      " it: 2870 | loss: 0.138 | acc: 0.970 - 950.35s\n",
      " it: 2880 | loss: 0.207 | acc: 0.920 - 952.47s\n",
      " it: 2890 | loss: 0.196 | acc: 0.940 - 954.64s\n",
      " it: 2900 | loss: 0.187 | acc: 0.920 - 956.81s\n",
      " --> test_loss: 0.348 | test_acc: 1.000\n",
      " it: 2910 | loss: 0.160 | acc: 0.950 - 967.44s\n",
      " it: 2920 | loss: 0.121 | acc: 0.930 - 969.75s\n",
      " it: 2930 | loss: 0.216 | acc: 0.920 - 971.98s\n",
      " it: 2940 | loss: 0.126 | acc: 0.960 - 974.08s\n",
      " it: 2950 | loss: 0.103 | acc: 0.980 - 976.58s\n",
      " it: 2960 | loss: 0.080 | acc: 0.980 - 979.44s\n",
      " it: 2970 | loss: 0.163 | acc: 0.940 - 982.42s\n",
      " it: 2980 | loss: 0.122 | acc: 0.960 - 985.32s\n",
      " it: 2990 | loss: 0.133 | acc: 0.950 - 988.04s\n",
      " it: 3000 | loss: 0.143 | acc: 0.960 - 990.50s\n",
      " --> test_loss: 0.369 | test_acc: 0.900\n",
      " * model saved at 'models/cnn'\n",
      " it: 3010 | loss: 0.142 | acc: 0.940 - 1003.27s\n",
      " it: 3020 | loss: 0.066 | acc: 0.970 - 1005.75s\n",
      " it: 3030 | loss: 0.057 | acc: 0.970 - 1008.14s\n",
      " it: 3040 | loss: 0.059 | acc: 0.980 - 1010.51s\n",
      " it: 3050 | loss: 0.036 | acc: 0.990 - 1012.79s\n",
      " it: 3060 | loss: 0.320 | acc: 0.870 - 1015.20s\n",
      " it: 3070 | loss: 0.079 | acc: 0.980 - 1017.44s\n",
      " it: 3080 | loss: 0.148 | acc: 0.940 - 1019.61s\n",
      " it: 3090 | loss: 0.047 | acc: 0.990 - 1022.42s\n",
      " it: 3100 | loss: 0.178 | acc: 0.950 - 1025.30s\n",
      " --> test_loss: 0.393 | test_acc: 0.900\n",
      " it: 3110 | loss: 0.055 | acc: 0.990 - 1037.24s\n",
      " it: 3120 | loss: 0.088 | acc: 0.980 - 1040.32s\n",
      " it: 3130 | loss: 0.126 | acc: 0.940 - 1042.88s\n",
      " it: 3140 | loss: 0.072 | acc: 0.980 - 1045.11s\n",
      " it: 3150 | loss: 0.042 | acc: 0.980 - 1047.32s\n",
      " it: 3160 | loss: 0.037 | acc: 0.990 - 1049.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it: 3170 | loss: 0.072 | acc: 0.960 - 1052.67s\n",
      " it: 3180 | loss: 0.154 | acc: 0.950 - 1055.67s\n",
      " it: 3190 | loss: 0.073 | acc: 0.960 - 1058.61s\n",
      " it: 3200 | loss: 0.101 | acc: 0.940 - 1061.68s\n",
      " --> test_loss: 0.416 | test_acc: 1.000\n",
      " it: 3210 | loss: 0.068 | acc: 0.980 - 1073.41s\n",
      " it: 3220 | loss: 0.091 | acc: 0.970 - 1075.70s\n",
      " it: 3230 | loss: 0.036 | acc: 0.980 - 1078.06s\n",
      " it: 3240 | loss: 0.060 | acc: 0.980 - 1080.31s\n",
      " it: 3250 | loss: 0.069 | acc: 0.960 - 1082.83s\n",
      " it: 3260 | loss: 0.143 | acc: 0.940 - 1085.19s\n",
      " it: 3270 | loss: 0.043 | acc: 0.990 - 1087.51s\n",
      " it: 3280 | loss: 0.043 | acc: 0.990 - 1090.02s\n",
      " it: 3290 | loss: 0.116 | acc: 0.960 - 1092.38s\n",
      " it: 3300 | loss: 0.033 | acc: 1.000 - 1094.74s\n",
      " --> test_loss: 0.395 | test_acc: 1.000\n",
      " it: 3310 | loss: 0.062 | acc: 0.980 - 1105.65s\n",
      " it: 3320 | loss: 0.069 | acc: 0.970 - 1107.95s\n",
      " it: 3330 | loss: 0.030 | acc: 0.990 - 1110.24s\n",
      " it: 3340 | loss: 0.123 | acc: 0.980 - 1112.79s\n",
      " it: 3350 | loss: 0.090 | acc: 0.960 - 1115.11s\n",
      " it: 3360 | loss: 0.027 | acc: 0.990 - 1117.34s\n",
      " it: 3370 | loss: 0.116 | acc: 0.960 - 1119.60s\n",
      " it: 3380 | loss: 0.075 | acc: 0.980 - 1121.84s\n",
      " it: 3390 | loss: 0.061 | acc: 0.990 - 1124.01s\n",
      " it: 3400 | loss: 0.065 | acc: 0.980 - 1126.40s\n",
      " --> test_loss: 0.440 | test_acc: 0.900\n",
      " it: 3410 | loss: 0.040 | acc: 0.980 - 1136.77s\n",
      " it: 3420 | loss: 0.079 | acc: 0.980 - 1138.92s\n",
      " it: 3430 | loss: 0.013 | acc: 1.000 - 1141.28s\n",
      " it: 3440 | loss: 0.101 | acc: 0.980 - 1143.63s\n",
      " it: 3450 | loss: 0.038 | acc: 0.990 - 1145.83s\n",
      " it: 3460 | loss: 0.052 | acc: 0.990 - 1148.13s\n",
      " it: 3470 | loss: 0.018 | acc: 1.000 - 1150.39s\n",
      " it: 3480 | loss: 0.022 | acc: 1.000 - 1152.57s\n",
      " it: 3490 | loss: 0.110 | acc: 0.970 - 1154.77s\n",
      " it: 3500 | loss: 0.010 | acc: 1.000 - 1157.49s\n",
      " --> test_loss: 0.501 | test_acc: 1.000\n",
      " it: 3510 | loss: 0.072 | acc: 0.970 - 1171.48s\n",
      " it: 3520 | loss: 0.098 | acc: 0.970 - 1174.29s\n",
      " it: 3530 | loss: 0.052 | acc: 0.980 - 1176.56s\n",
      " it: 3540 | loss: 0.076 | acc: 0.980 - 1178.81s\n",
      " it: 3550 | loss: 0.084 | acc: 0.980 - 1181.28s\n",
      " it: 3560 | loss: 0.091 | acc: 0.970 - 1183.61s\n",
      " it: 3570 | loss: 0.066 | acc: 0.990 - 1186.23s\n",
      " it: 3580 | loss: 0.117 | acc: 0.970 - 1189.72s\n",
      " it: 3590 | loss: 0.016 | acc: 1.000 - 1192.32s\n",
      " it: 3600 | loss: 0.017 | acc: 1.000 - 1194.62s\n",
      " --> test_loss: 0.531 | test_acc: 1.000\n",
      " it: 3610 | loss: 0.044 | acc: 0.990 - 1205.97s\n",
      " it: 3620 | loss: 0.035 | acc: 0.990 - 1208.33s\n",
      " it: 3630 | loss: 0.025 | acc: 0.990 - 1210.63s\n",
      " it: 3640 | loss: 0.013 | acc: 1.000 - 1212.95s\n",
      " it: 3650 | loss: 0.008 | acc: 1.000 - 1216.34s\n",
      " it: 3660 | loss: 0.006 | acc: 1.000 - 1219.44s\n",
      " it: 3670 | loss: 0.047 | acc: 0.990 - 1221.79s\n",
      " it: 3680 | loss: 0.063 | acc: 0.990 - 1224.04s\n",
      " it: 3690 | loss: 0.007 | acc: 1.000 - 1226.38s\n",
      " it: 3700 | loss: 0.052 | acc: 0.970 - 1228.71s\n",
      " --> test_loss: 0.459 | test_acc: 1.000\n",
      " it: 3710 | loss: 0.027 | acc: 0.990 - 1242.24s\n",
      " it: 3720 | loss: 0.062 | acc: 0.960 - 1245.33s\n",
      " it: 3730 | loss: 0.026 | acc: 0.990 - 1248.39s\n",
      " it: 3740 | loss: 0.010 | acc: 1.000 - 1251.26s\n",
      " it: 3750 | loss: 0.029 | acc: 0.990 - 1254.32s\n",
      " it: 3760 | loss: 0.043 | acc: 0.990 - 1257.28s\n",
      " it: 3770 | loss: 0.074 | acc: 0.980 - 1259.98s\n",
      " it: 3780 | loss: 0.014 | acc: 1.000 - 1262.29s\n",
      " it: 3790 | loss: 0.051 | acc: 0.970 - 1264.83s\n",
      " it: 3800 | loss: 0.047 | acc: 0.990 - 1267.88s\n",
      " --> test_loss: 0.507 | test_acc: 1.000\n",
      " it: 3810 | loss: 0.065 | acc: 0.990 - 1280.57s\n",
      " it: 3820 | loss: 0.118 | acc: 0.960 - 1282.70s\n",
      " it: 3830 | loss: 0.100 | acc: 0.970 - 1284.81s\n",
      " it: 3840 | loss: 0.096 | acc: 0.970 - 1286.93s\n",
      " it: 3850 | loss: 0.038 | acc: 0.990 - 1289.02s\n",
      " it: 3860 | loss: 0.063 | acc: 0.970 - 1291.12s\n",
      " it: 3870 | loss: 0.037 | acc: 0.980 - 1293.16s\n",
      " it: 3880 | loss: 0.059 | acc: 0.980 - 1295.36s\n",
      " it: 3890 | loss: 0.076 | acc: 0.980 - 1297.53s\n",
      " it: 3900 | loss: 0.054 | acc: 0.990 - 1299.59s\n",
      " --> test_loss: 0.482 | test_acc: 1.000\n",
      " it: 3910 | loss: 0.024 | acc: 1.000 - 1309.45s\n",
      " it: 3920 | loss: 0.073 | acc: 0.970 - 1311.56s\n",
      " it: 3930 | loss: 0.057 | acc: 0.960 - 1313.70s\n",
      " it: 3940 | loss: 0.021 | acc: 0.990 - 1315.79s\n",
      " it: 3950 | loss: 0.059 | acc: 0.980 - 1317.87s\n",
      " it: 3960 | loss: 0.052 | acc: 0.980 - 1319.98s\n",
      " it: 3970 | loss: 0.037 | acc: 1.000 - 1322.11s\n",
      " it: 3980 | loss: 0.046 | acc: 0.980 - 1324.19s\n",
      " it: 3990 | loss: 0.041 | acc: 0.990 - 1326.32s\n",
      " it: 4000 | loss: 0.038 | acc: 0.990 - 1328.40s\n",
      " --> test_loss: 0.527 | test_acc: 1.000\n",
      " * model saved at 'models/cnn'\n",
      " it: 4010 | loss: 0.013 | acc: 1.000 - 1338.79s\n",
      " it: 4020 | loss: 0.040 | acc: 0.990 - 1341.16s\n",
      " it: 4030 | loss: 0.014 | acc: 1.000 - 1343.34s\n",
      " it: 4040 | loss: 0.013 | acc: 0.990 - 1345.40s\n",
      " it: 4050 | loss: 0.247 | acc: 0.950 - 1347.46s\n",
      " it: 4060 | loss: 0.025 | acc: 0.990 - 1349.59s\n",
      " it: 4070 | loss: 0.069 | acc: 0.980 - 1351.69s\n",
      " it: 4080 | loss: 0.059 | acc: 0.980 - 1353.80s\n",
      " it: 4090 | loss: 0.035 | acc: 0.980 - 1356.42s\n",
      " it: 4100 | loss: 0.020 | acc: 1.000 - 1359.19s\n",
      " --> test_loss: 0.439 | test_acc: 1.000\n",
      " it: 4110 | loss: 0.060 | acc: 0.980 - 1369.28s\n",
      " it: 4120 | loss: 0.011 | acc: 1.000 - 1372.10s\n",
      " it: 4130 | loss: 0.061 | acc: 0.980 - 1374.90s\n",
      " it: 4140 | loss: 0.043 | acc: 0.980 - 1377.58s\n",
      " it: 4150 | loss: 0.042 | acc: 0.980 - 1379.85s\n",
      " it: 4160 | loss: 0.060 | acc: 0.990 - 1381.95s\n",
      " it: 4170 | loss: 0.066 | acc: 0.970 - 1384.09s\n",
      " it: 4180 | loss: 0.093 | acc: 0.960 - 1386.19s\n",
      " it: 4190 | loss: 0.016 | acc: 1.000 - 1388.37s\n",
      " it: 4200 | loss: 0.031 | acc: 0.980 - 1390.61s\n",
      " --> test_loss: 0.387 | test_acc: 1.000\n",
      " it: 4210 | loss: 0.066 | acc: 0.980 - 1400.50s\n",
      " it: 4220 | loss: 0.028 | acc: 0.990 - 1402.65s\n",
      " it: 4230 | loss: 0.045 | acc: 0.980 - 1404.75s\n",
      " it: 4240 | loss: 0.011 | acc: 1.000 - 1406.90s\n",
      " it: 4250 | loss: 0.042 | acc: 0.990 - 1408.95s\n",
      " it: 4260 | loss: 0.043 | acc: 0.990 - 1411.08s\n",
      " it: 4270 | loss: 0.006 | acc: 1.000 - 1413.18s\n",
      " it: 4280 | loss: 0.050 | acc: 0.990 - 1415.38s\n",
      " it: 4290 | loss: 0.022 | acc: 0.990 - 1417.57s\n",
      " it: 4300 | loss: 0.040 | acc: 0.990 - 1419.72s\n",
      " --> test_loss: 0.630 | test_acc: 1.000\n",
      " it: 4310 | loss: 0.027 | acc: 0.990 - 1429.52s\n",
      " it: 4320 | loss: 0.009 | acc: 1.000 - 1431.62s\n",
      " it: 4330 | loss: 0.033 | acc: 1.000 - 1433.74s\n",
      " it: 4340 | loss: 0.033 | acc: 0.980 - 1435.86s\n",
      " it: 4350 | loss: 0.032 | acc: 0.980 - 1438.02s\n",
      " it: 4360 | loss: 0.086 | acc: 0.970 - 1440.13s\n",
      " it: 4370 | loss: 0.034 | acc: 0.980 - 1442.26s\n",
      " it: 4380 | loss: 0.024 | acc: 0.990 - 1444.35s\n",
      " it: 4390 | loss: 0.069 | acc: 0.990 - 1446.47s\n",
      " it: 4400 | loss: 0.070 | acc: 0.980 - 1448.59s\n",
      " --> test_loss: 0.476 | test_acc: 1.000\n",
      " it: 4410 | loss: 0.047 | acc: 0.970 - 1458.41s\n",
      " it: 4420 | loss: 0.030 | acc: 0.980 - 1460.52s\n",
      " it: 4430 | loss: 0.044 | acc: 0.980 - 1462.65s\n",
      " it: 4440 | loss: 0.039 | acc: 0.990 - 1464.77s\n",
      " it: 4450 | loss: 0.091 | acc: 0.960 - 1466.86s\n",
      " it: 4460 | loss: 0.062 | acc: 0.980 - 1469.00s\n",
      " it: 4470 | loss: 0.015 | acc: 1.000 - 1471.07s\n",
      " it: 4480 | loss: 0.041 | acc: 0.980 - 1473.20s\n",
      " it: 4490 | loss: 0.020 | acc: 1.000 - 1475.35s\n",
      " it: 4500 | loss: 0.026 | acc: 1.000 - 1477.46s\n",
      " --> test_loss: 0.438 | test_acc: 1.000\n",
      " it: 4510 | loss: 0.007 | acc: 1.000 - 1487.16s\n",
      " it: 4520 | loss: 0.007 | acc: 1.000 - 1489.22s\n",
      " it: 4530 | loss: 0.102 | acc: 0.970 - 1491.36s\n",
      " it: 4540 | loss: 0.019 | acc: 0.990 - 1493.46s\n",
      " it: 4550 | loss: 0.017 | acc: 0.990 - 1495.55s\n",
      " it: 4560 | loss: 0.020 | acc: 1.000 - 1497.65s\n",
      " it: 4570 | loss: 0.025 | acc: 0.990 - 1499.74s\n",
      " it: 4580 | loss: 0.026 | acc: 0.980 - 1501.82s\n",
      " it: 4590 | loss: 0.033 | acc: 0.980 - 1503.92s\n",
      " it: 4600 | loss: 0.031 | acc: 0.990 - 1506.59s\n",
      " --> test_loss: 0.536 | test_acc: 1.000\n",
      " it: 4610 | loss: 0.059 | acc: 0.980 - 1518.76s\n",
      " it: 4620 | loss: 0.006 | acc: 1.000 - 1520.91s\n",
      " it: 4630 | loss: 0.045 | acc: 0.980 - 1522.97s\n",
      " it: 4640 | loss: 0.073 | acc: 0.970 - 1525.07s\n",
      " it: 4650 | loss: 0.010 | acc: 1.000 - 1527.14s\n",
      " it: 4660 | loss: 0.127 | acc: 0.960 - 1529.23s\n",
      " it: 4670 | loss: 0.038 | acc: 0.990 - 1531.44s\n",
      " it: 4680 | loss: 0.191 | acc: 0.930 - 1533.57s\n",
      " it: 4690 | loss: 0.020 | acc: 1.000 - 1535.77s\n",
      " it: 4700 | loss: 0.049 | acc: 0.990 - 1537.86s\n",
      " --> test_loss: 0.512 | test_acc: 1.000\n",
      " it: 4710 | loss: 0.009 | acc: 1.000 - 1547.65s\n",
      " it: 4720 | loss: 0.017 | acc: 0.990 - 1549.99s\n",
      " it: 4730 | loss: 0.054 | acc: 0.990 - 1552.79s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it: 4740 | loss: 0.005 | acc: 1.000 - 1555.46s\n",
      " it: 4750 | loss: 0.098 | acc: 0.980 - 1557.94s\n",
      " it: 4760 | loss: 0.010 | acc: 1.000 - 1560.06s\n",
      " it: 4770 | loss: 0.113 | acc: 0.970 - 1562.23s\n",
      " it: 4780 | loss: 0.034 | acc: 0.990 - 1564.34s\n",
      " it: 4790 | loss: 0.096 | acc: 0.980 - 1566.47s\n",
      " it: 4800 | loss: 0.012 | acc: 1.000 - 1568.58s\n",
      " --> test_loss: 0.563 | test_acc: 1.000\n",
      " it: 4810 | loss: 0.013 | acc: 1.000 - 1578.34s\n",
      " it: 4820 | loss: 0.033 | acc: 0.990 - 1580.88s\n",
      " it: 4830 | loss: 0.039 | acc: 0.980 - 1583.69s\n",
      " it: 4840 | loss: 0.048 | acc: 0.990 - 1586.40s\n",
      " it: 4850 | loss: 0.009 | acc: 1.000 - 1589.14s\n",
      " it: 4860 | loss: 0.075 | acc: 0.980 - 1591.88s\n",
      " it: 4870 | loss: 0.026 | acc: 0.990 - 1594.65s\n",
      " it: 4880 | loss: 0.063 | acc: 0.970 - 1597.40s\n",
      " it: 4890 | loss: 0.063 | acc: 0.990 - 1599.97s\n",
      " it: 4900 | loss: 0.010 | acc: 1.000 - 1602.43s\n",
      " --> test_loss: 0.475 | test_acc: 1.000\n",
      " it: 4910 | loss: 0.021 | acc: 0.990 - 1612.18s\n",
      " it: 4920 | loss: 0.017 | acc: 0.990 - 1614.76s\n",
      " it: 4930 | loss: 0.011 | acc: 0.990 - 1617.48s\n",
      " it: 4940 | loss: 0.003 | acc: 1.000 - 1620.17s\n",
      " it: 4950 | loss: 0.009 | acc: 1.000 - 1622.74s\n",
      " it: 4960 | loss: 0.007 | acc: 1.000 - 1624.78s\n",
      " it: 4970 | loss: 0.004 | acc: 1.000 - 1626.89s\n",
      " it: 4980 | loss: 0.050 | acc: 0.980 - 1629.39s\n",
      " it: 4990 | loss: 0.066 | acc: 0.970 - 1631.54s\n",
      " it: 5000 | loss: 0.036 | acc: 0.990 - 1633.64s\n",
      " --> test_loss: 0.603 | test_acc: 1.000\n",
      " * model saved at 'models/cnn'\n",
      " it: 5010 | loss: 0.006 | acc: 1.000 - 1644.02s\n",
      " it: 5020 | loss: 0.020 | acc: 0.990 - 1646.14s\n",
      " it: 5030 | loss: 0.088 | acc: 0.980 - 1648.21s\n",
      " it: 5040 | loss: 0.037 | acc: 0.980 - 1650.31s\n",
      " it: 5050 | loss: 0.053 | acc: 0.980 - 1652.45s\n",
      " it: 5060 | loss: 0.053 | acc: 0.990 - 1654.63s\n",
      " it: 5070 | loss: 0.039 | acc: 0.990 - 1656.74s\n",
      " it: 5080 | loss: 0.012 | acc: 0.990 - 1659.11s\n",
      " it: 5090 | loss: 0.023 | acc: 0.990 - 1661.89s\n",
      " it: 5100 | loss: 0.013 | acc: 1.000 - 1664.42s\n",
      " --> test_loss: 0.513 | test_acc: 1.000\n",
      " it: 5110 | loss: 0.010 | acc: 0.990 - 1674.63s\n",
      " it: 5120 | loss: 0.004 | acc: 1.000 - 1676.91s\n",
      " it: 5130 | loss: 0.047 | acc: 0.990 - 1679.09s\n",
      " it: 5140 | loss: 0.026 | acc: 0.990 - 1681.14s\n",
      " it: 5150 | loss: 0.026 | acc: 0.990 - 1683.20s\n",
      " it: 5160 | loss: 0.021 | acc: 0.990 - 1685.30s\n",
      " it: 5170 | loss: 0.016 | acc: 0.990 - 1687.42s\n",
      " it: 5180 | loss: 0.002 | acc: 1.000 - 1690.12s\n",
      " it: 5190 | loss: 0.003 | acc: 1.000 - 1692.77s\n",
      " it: 5200 | loss: 0.015 | acc: 0.990 - 1695.26s\n",
      " --> test_loss: 0.695 | test_acc: 1.000\n",
      " it: 5210 | loss: 0.027 | acc: 0.990 - 1705.58s\n",
      " it: 5220 | loss: 0.021 | acc: 0.990 - 1708.24s\n",
      " it: 5230 | loss: 0.012 | acc: 0.990 - 1710.65s\n",
      " it: 5240 | loss: 0.013 | acc: 0.990 - 1712.74s\n",
      " it: 5250 | loss: 0.010 | acc: 1.000 - 1714.80s\n",
      " it: 5260 | loss: 0.011 | acc: 0.990 - 1716.89s\n",
      " it: 5270 | loss: 0.010 | acc: 0.990 - 1719.07s\n",
      " it: 5280 | loss: 0.018 | acc: 0.990 - 1721.24s\n",
      " it: 5290 | loss: 0.015 | acc: 0.990 - 1723.28s\n",
      " it: 5300 | loss: 0.014 | acc: 0.990 - 1725.45s\n",
      " --> test_loss: 0.617 | test_acc: 1.000\n",
      " it: 5310 | loss: 0.005 | acc: 1.000 - 1735.30s\n",
      " it: 5320 | loss: 0.006 | acc: 1.000 - 1737.40s\n",
      " it: 5330 | loss: 0.001 | acc: 1.000 - 1739.57s\n",
      " it: 5340 | loss: 0.002 | acc: 1.000 - 1741.70s\n",
      " it: 5350 | loss: 0.001 | acc: 1.000 - 1743.85s\n",
      " it: 5360 | loss: 0.003 | acc: 1.000 - 1745.97s\n",
      " it: 5370 | loss: 0.000 | acc: 1.000 - 1748.08s\n",
      " it: 5380 | loss: 0.042 | acc: 0.990 - 1750.24s\n",
      " it: 5390 | loss: 0.026 | acc: 0.990 - 1752.38s\n",
      " it: 5400 | loss: 0.004 | acc: 1.000 - 1754.47s\n",
      " --> test_loss: 0.611 | test_acc: 1.000\n",
      " it: 5410 | loss: 0.040 | acc: 0.990 - 1764.79s\n",
      " it: 5420 | loss: 0.003 | acc: 1.000 - 1767.38s\n",
      " it: 5430 | loss: 0.010 | acc: 1.000 - 1769.91s\n",
      " it: 5440 | loss: 0.003 | acc: 1.000 - 1772.03s\n",
      " it: 5450 | loss: 0.002 | acc: 1.000 - 1774.22s\n",
      " it: 5460 | loss: 0.001 | acc: 1.000 - 1776.38s\n",
      " it: 5470 | loss: 0.026 | acc: 0.990 - 1778.47s\n",
      " it: 5480 | loss: 0.009 | acc: 0.990 - 1780.65s\n",
      " it: 5490 | loss: 0.012 | acc: 1.000 - 1782.80s\n",
      " it: 5500 | loss: 0.062 | acc: 0.990 - 1784.91s\n",
      " --> test_loss: 0.770 | test_acc: 0.900\n",
      " it: 5510 | loss: 0.002 | acc: 1.000 - 1795.38s\n",
      " it: 5520 | loss: 0.001 | acc: 1.000 - 1798.08s\n",
      " it: 5530 | loss: 0.011 | acc: 0.990 - 1800.70s\n",
      " it: 5540 | loss: 0.012 | acc: 0.990 - 1802.93s\n",
      " it: 5550 | loss: 0.007 | acc: 1.000 - 1805.02s\n",
      " it: 5560 | loss: 0.011 | acc: 0.990 - 1807.10s\n",
      " it: 5570 | loss: 0.001 | acc: 1.000 - 1809.30s\n",
      " it: 5580 | loss: 0.001 | acc: 1.000 - 1811.36s\n",
      " it: 5590 | loss: 0.001 | acc: 1.000 - 1813.89s\n",
      " it: 5600 | loss: 0.005 | acc: 1.000 - 1816.19s\n",
      " --> test_loss: 0.669 | test_acc: 1.000\n",
      " it: 5610 | loss: 0.003 | acc: 1.000 - 1826.85s\n",
      " it: 5620 | loss: 0.002 | acc: 1.000 - 1829.71s\n",
      " it: 5630 | loss: 0.001 | acc: 1.000 - 1832.59s\n",
      " it: 5640 | loss: 0.000 | acc: 1.000 - 1835.34s\n",
      " it: 5650 | loss: 0.001 | acc: 1.000 - 1838.00s\n",
      " it: 5660 | loss: 0.002 | acc: 1.000 - 1840.81s\n",
      " it: 5670 | loss: 0.000 | acc: 1.000 - 1843.50s\n",
      " it: 5680 | loss: 0.005 | acc: 1.000 - 1846.19s\n",
      " it: 5690 | loss: 0.000 | acc: 1.000 - 1848.71s\n",
      " it: 5700 | loss: 0.001 | acc: 1.000 - 1851.01s\n",
      " --> test_loss: 0.814 | test_acc: 1.000\n",
      " it: 5710 | loss: 0.002 | acc: 1.000 - 1860.54s\n",
      " it: 5720 | loss: 0.002 | acc: 1.000 - 1862.64s\n",
      " it: 5730 | loss: 0.000 | acc: 1.000 - 1864.71s\n",
      " it: 5740 | loss: 0.001 | acc: 1.000 - 1866.81s\n",
      " it: 5750 | loss: 0.000 | acc: 1.000 - 1869.18s\n",
      " it: 5760 | loss: 0.000 | acc: 1.000 - 1871.86s\n",
      " it: 5770 | loss: 0.000 | acc: 1.000 - 1874.55s\n",
      " it: 5780 | loss: 0.000 | acc: 1.000 - 1877.27s\n",
      " it: 5790 | loss: 0.069 | acc: 0.990 - 1879.92s\n",
      " it: 5800 | loss: 0.000 | acc: 1.000 - 1882.46s\n",
      " --> test_loss: 0.699 | test_acc: 1.000\n",
      " it: 5810 | loss: 0.001 | acc: 1.000 - 1894.50s\n",
      " it: 5820 | loss: 0.007 | acc: 1.000 - 1896.88s\n",
      " it: 5830 | loss: 0.000 | acc: 1.000 - 1898.99s\n",
      " it: 5840 | loss: 0.002 | acc: 1.000 - 1901.11s\n",
      " it: 5850 | loss: 0.008 | acc: 0.990 - 1903.18s\n",
      " it: 5860 | loss: 0.000 | acc: 1.000 - 1905.40s\n",
      " it: 5870 | loss: 0.013 | acc: 0.990 - 1908.10s\n",
      " it: 5880 | loss: 0.004 | acc: 1.000 - 1910.59s\n",
      " it: 5890 | loss: 0.002 | acc: 1.000 - 1912.71s\n",
      " it: 5900 | loss: 0.001 | acc: 1.000 - 1914.80s\n",
      " --> test_loss: 0.668 | test_acc: 1.000\n",
      " it: 5910 | loss: 0.006 | acc: 1.000 - 1924.34s\n",
      " it: 5920 | loss: 0.042 | acc: 0.990 - 1926.53s\n",
      " it: 5930 | loss: 0.001 | acc: 1.000 - 1928.59s\n",
      " it: 5940 | loss: 0.007 | acc: 1.000 - 1930.67s\n",
      " it: 5950 | loss: 0.003 | acc: 1.000 - 1932.78s\n",
      " it: 5960 | loss: 0.003 | acc: 1.000 - 1934.83s\n",
      " it: 5970 | loss: 0.002 | acc: 1.000 - 1936.96s\n",
      " it: 5980 | loss: 0.000 | acc: 1.000 - 1939.07s\n",
      " it: 5990 | loss: 0.000 | acc: 1.000 - 1941.18s\n",
      " it: 6000 | loss: 0.000 | acc: 1.000 - 1943.31s\n",
      " --> test_loss: 0.690 | test_acc: 1.000\n",
      " * model saved at 'models/cnn'\n",
      " it: 6010 | loss: 0.001 | acc: 1.000 - 1953.72s\n",
      " it: 6020 | loss: 0.008 | acc: 0.990 - 1955.89s\n",
      " it: 6030 | loss: 0.002 | acc: 1.000 - 1957.96s\n",
      " it: 6040 | loss: 0.008 | acc: 1.000 - 1960.12s\n",
      " it: 6050 | loss: 0.002 | acc: 1.000 - 1962.19s\n",
      " it: 6060 | loss: 0.003 | acc: 1.000 - 1964.26s\n",
      " it: 6070 | loss: 0.004 | acc: 1.000 - 1966.70s\n",
      " it: 6080 | loss: 0.049 | acc: 0.990 - 1968.79s\n",
      " it: 6090 | loss: 0.000 | acc: 1.000 - 1970.87s\n",
      " it: 6100 | loss: 0.000 | acc: 1.000 - 1972.95s\n",
      " --> test_loss: 0.762 | test_acc: 1.000\n",
      " it: 6110 | loss: 0.001 | acc: 1.000 - 1983.27s\n",
      " it: 6120 | loss: 0.001 | acc: 1.000 - 1986.02s\n",
      " it: 6130 | loss: 0.001 | acc: 1.000 - 1988.73s\n",
      " it: 6140 | loss: 0.001 | acc: 1.000 - 1990.99s\n",
      " it: 6150 | loss: 0.000 | acc: 1.000 - 1993.06s\n",
      " it: 6160 | loss: 0.001 | acc: 1.000 - 1995.37s\n",
      " it: 6170 | loss: 0.001 | acc: 1.000 - 1998.08s\n",
      " it: 6180 | loss: 0.000 | acc: 1.000 - 2000.76s\n",
      " it: 6190 | loss: 0.011 | acc: 0.990 - 2003.03s\n",
      " it: 6200 | loss: 0.001 | acc: 1.000 - 2005.12s\n",
      " --> test_loss: 0.717 | test_acc: 1.000\n",
      " it: 6210 | loss: 0.001 | acc: 1.000 - 2016.12s\n",
      " it: 6220 | loss: 0.001 | acc: 1.000 - 2018.81s\n",
      " it: 6230 | loss: 0.001 | acc: 1.000 - 2021.54s\n",
      " it: 6240 | loss: 0.000 | acc: 1.000 - 2023.90s\n",
      " it: 6250 | loss: 0.000 | acc: 1.000 - 2026.47s\n",
      " it: 6260 | loss: 0.001 | acc: 1.000 - 2029.04s\n",
      " it: 6270 | loss: 0.051 | acc: 0.990 - 2031.80s\n",
      " it: 6280 | loss: 0.001 | acc: 1.000 - 2034.36s\n",
      " it: 6290 | loss: 0.006 | acc: 1.000 - 2036.72s\n",
      " it: 6300 | loss: 0.001 | acc: 1.000 - 2038.84s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> test_loss: 0.812 | test_acc: 1.000\n",
      " it: 6310 | loss: 0.001 | acc: 1.000 - 2048.65s\n",
      " it: 6320 | loss: 0.000 | acc: 1.000 - 2050.74s\n",
      " it: 6330 | loss: 0.000 | acc: 1.000 - 2052.80s\n",
      " it: 6340 | loss: 0.004 | acc: 1.000 - 2054.93s\n",
      " it: 6350 | loss: 0.002 | acc: 1.000 - 2057.09s\n",
      " it: 6360 | loss: 0.000 | acc: 1.000 - 2059.17s\n",
      " it: 6370 | loss: 0.001 | acc: 1.000 - 2061.18s\n",
      " it: 6380 | loss: 0.000 | acc: 1.000 - 2063.25s\n",
      " it: 6390 | loss: 0.000 | acc: 1.000 - 2065.29s\n",
      " it: 6400 | loss: 0.000 | acc: 1.000 - 2067.35s\n",
      " --> test_loss: 0.840 | test_acc: 1.000\n",
      " it: 6410 | loss: 0.000 | acc: 1.000 - 2077.11s\n",
      " it: 6420 | loss: 0.000 | acc: 1.000 - 2079.18s\n",
      " it: 6430 | loss: 0.000 | acc: 1.000 - 2081.33s\n",
      " it: 6440 | loss: 0.000 | acc: 1.000 - 2083.33s\n",
      " it: 6450 | loss: 0.001 | acc: 1.000 - 2085.40s\n",
      " it: 6460 | loss: 0.000 | acc: 1.000 - 2087.46s\n",
      " it: 6470 | loss: 0.000 | acc: 1.000 - 2089.50s\n",
      " it: 6480 | loss: 0.000 | acc: 1.000 - 2091.57s\n",
      " it: 6490 | loss: 0.000 | acc: 1.000 - 2093.68s\n",
      " it: 6500 | loss: 0.000 | acc: 1.000 - 2095.76s\n",
      " --> test_loss: 0.882 | test_acc: 1.000\n",
      " it: 6510 | loss: 0.001 | acc: 1.000 - 2105.99s\n",
      " it: 6520 | loss: 0.000 | acc: 1.000 - 2108.01s\n",
      " it: 6530 | loss: 0.000 | acc: 1.000 - 2110.11s\n",
      " it: 6540 | loss: 0.001 | acc: 1.000 - 2112.29s\n",
      " it: 6550 | loss: 0.063 | acc: 0.990 - 2114.39s\n",
      " it: 6560 | loss: 0.000 | acc: 1.000 - 2116.99s\n",
      " it: 6570 | loss: 0.004 | acc: 1.000 - 2119.66s\n",
      " it: 6580 | loss: 0.027 | acc: 0.990 - 2122.15s\n",
      " it: 6590 | loss: 0.001 | acc: 1.000 - 2124.66s\n",
      " it: 6600 | loss: 0.002 | acc: 1.000 - 2126.97s\n",
      " --> test_loss: 0.849 | test_acc: 1.000\n",
      " it: 6610 | loss: 0.001 | acc: 1.000 - 2136.48s\n",
      " it: 6620 | loss: 0.001 | acc: 1.000 - 2138.59s\n",
      " it: 6630 | loss: 0.005 | acc: 1.000 - 2140.67s\n",
      " it: 6640 | loss: 0.000 | acc: 1.000 - 2142.76s\n",
      " it: 6650 | loss: 0.001 | acc: 1.000 - 2144.91s\n",
      " it: 6660 | loss: 0.001 | acc: 1.000 - 2147.60s\n",
      " it: 6670 | loss: 0.002 | acc: 1.000 - 2150.34s\n",
      " it: 6680 | loss: 0.000 | acc: 1.000 - 2153.07s\n",
      " it: 6690 | loss: 0.000 | acc: 1.000 - 2155.79s\n",
      " it: 6700 | loss: 0.000 | acc: 1.000 - 2158.62s\n",
      " --> test_loss: 0.838 | test_acc: 1.000\n",
      " it: 6710 | loss: 0.000 | acc: 1.000 - 2169.53s\n",
      " it: 6720 | loss: 0.000 | acc: 1.000 - 2171.66s\n",
      " it: 6730 | loss: 0.000 | acc: 1.000 - 2173.73s\n",
      " it: 6740 | loss: 0.000 | acc: 1.000 - 2175.83s\n",
      " it: 6750 | loss: 0.000 | acc: 1.000 - 2177.91s\n",
      " it: 6760 | loss: 0.000 | acc: 1.000 - 2179.95s\n",
      " it: 6770 | loss: 0.000 | acc: 1.000 - 2182.07s\n",
      " it: 6780 | loss: 0.000 | acc: 1.000 - 2184.14s\n",
      " it: 6790 | loss: 0.000 | acc: 1.000 - 2186.22s\n",
      " it: 6800 | loss: 0.000 | acc: 1.000 - 2188.30s\n",
      " --> test_loss: 1.014 | test_acc: 1.000\n",
      " it: 6810 | loss: 0.000 | acc: 1.000 - 2200.14s\n",
      " it: 6820 | loss: 0.000 | acc: 1.000 - 2202.81s\n",
      " it: 6830 | loss: 0.000 | acc: 1.000 - 2205.48s\n",
      " it: 6840 | loss: 0.001 | acc: 1.000 - 2208.06s\n",
      " it: 6850 | loss: 0.027 | acc: 0.990 - 2210.67s\n",
      " it: 6860 | loss: 0.019 | acc: 0.990 - 2212.82s\n",
      " it: 6870 | loss: 0.000 | acc: 1.000 - 2214.94s\n",
      " it: 6880 | loss: 0.001 | acc: 1.000 - 2217.26s\n",
      " it: 6890 | loss: 0.001 | acc: 1.000 - 2219.31s\n",
      " it: 6900 | loss: 0.031 | acc: 0.990 - 2221.36s\n",
      " --> test_loss: 0.689 | test_acc: 1.000\n",
      " it: 6910 | loss: 0.001 | acc: 1.000 - 2233.05s\n",
      " it: 6920 | loss: 0.001 | acc: 1.000 - 2235.70s\n",
      " it: 6930 | loss: 0.000 | acc: 1.000 - 2238.27s\n",
      " it: 6940 | loss: 0.001 | acc: 1.000 - 2240.75s\n",
      " it: 6950 | loss: 0.000 | acc: 1.000 - 2242.85s\n",
      " it: 6960 | loss: 0.000 | acc: 1.000 - 2244.89s\n",
      " it: 6970 | loss: 0.000 | acc: 1.000 - 2247.05s\n",
      " it: 6980 | loss: 0.001 | acc: 1.000 - 2249.11s\n",
      " it: 6990 | loss: 0.001 | acc: 1.000 - 2251.15s\n",
      " it: 7000 | loss: 0.001 | acc: 1.000 - 2253.26s\n",
      " --> test_loss: 0.792 | test_acc: 1.000\n",
      " * model saved at 'models/cnn'\n",
      " it: 7010 | loss: 0.000 | acc: 1.000 - 2264.57s\n",
      " it: 7020 | loss: 0.000 | acc: 1.000 - 2266.69s\n",
      " it: 7030 | loss: 0.000 | acc: 1.000 - 2268.74s\n",
      " it: 7040 | loss: 0.000 | acc: 1.000 - 2270.88s\n",
      " it: 7050 | loss: 0.000 | acc: 1.000 - 2273.35s\n",
      " it: 7060 | loss: 0.000 | acc: 1.000 - 2275.61s\n",
      " it: 7070 | loss: 0.000 | acc: 1.000 - 2277.75s\n",
      " it: 7080 | loss: 0.000 | acc: 1.000 - 2280.07s\n",
      " it: 7090 | loss: 0.000 | acc: 1.000 - 2282.10s\n",
      " it: 7100 | loss: 0.000 | acc: 1.000 - 2284.18s\n",
      " --> test_loss: 0.969 | test_acc: 1.000\n",
      " it: 7110 | loss: 0.000 | acc: 1.000 - 2293.86s\n",
      " it: 7120 | loss: 0.001 | acc: 1.000 - 2295.88s\n",
      " it: 7130 | loss: 0.021 | acc: 0.990 - 2297.88s\n",
      " it: 7140 | loss: 0.019 | acc: 0.990 - 2299.89s\n",
      " it: 7150 | loss: 0.002 | acc: 1.000 - 2302.23s\n",
      " it: 7160 | loss: 0.021 | acc: 0.990 - 2304.90s\n",
      " it: 7170 | loss: 0.002 | acc: 1.000 - 2307.55s\n",
      " it: 7180 | loss: 0.003 | acc: 1.000 - 2310.25s\n",
      " it: 7190 | loss: 0.007 | acc: 1.000 - 2312.63s\n",
      " it: 7200 | loss: 0.005 | acc: 1.000 - 2314.72s\n",
      " --> test_loss: 0.692 | test_acc: 1.000\n",
      " it: 7210 | loss: 0.003 | acc: 1.000 - 2325.28s\n",
      " it: 7220 | loss: 0.047 | acc: 0.990 - 2327.36s\n",
      " it: 7230 | loss: 0.060 | acc: 0.980 - 2329.44s\n",
      " it: 7240 | loss: 0.008 | acc: 1.000 - 2331.52s\n",
      " it: 7250 | loss: 0.065 | acc: 0.990 - 2334.20s\n",
      " it: 7260 | loss: 0.013 | acc: 0.990 - 2336.84s\n",
      " it: 7270 | loss: 0.032 | acc: 0.990 - 2339.43s\n",
      " it: 7280 | loss: 0.027 | acc: 0.990 - 2341.73s\n",
      " it: 7290 | loss: 0.055 | acc: 0.980 - 2343.83s\n",
      " it: 7300 | loss: 0.002 | acc: 1.000 - 2345.86s\n",
      " --> test_loss: 0.850 | test_acc: 1.000\n",
      " it: 7310 | loss: 0.001 | acc: 1.000 - 2355.45s\n",
      " it: 7320 | loss: 0.003 | acc: 1.000 - 2357.51s\n",
      " it: 7330 | loss: 0.002 | acc: 1.000 - 2359.57s\n",
      " it: 7340 | loss: 0.000 | acc: 1.000 - 2361.71s\n",
      " it: 7350 | loss: 0.001 | acc: 1.000 - 2363.78s\n",
      " it: 7360 | loss: 0.051 | acc: 0.990 - 2365.87s\n",
      " it: 7370 | loss: 0.002 | acc: 1.000 - 2367.96s\n",
      " it: 7380 | loss: 0.002 | acc: 1.000 - 2370.00s\n",
      " it: 7390 | loss: 0.056 | acc: 0.980 - 2372.07s\n",
      " it: 7400 | loss: 0.017 | acc: 0.990 - 2374.13s\n",
      " --> test_loss: 0.776 | test_acc: 1.000\n",
      " it: 7410 | loss: 0.022 | acc: 0.990 - 2383.58s\n",
      " it: 7420 | loss: 0.003 | acc: 1.000 - 2385.66s\n",
      " it: 7430 | loss: 0.006 | acc: 1.000 - 2387.74s\n",
      " it: 7440 | loss: 0.025 | acc: 0.990 - 2389.83s\n",
      " it: 7450 | loss: 0.002 | acc: 1.000 - 2391.87s\n",
      " it: 7460 | loss: 0.019 | acc: 0.990 - 2393.97s\n",
      " it: 7470 | loss: 0.018 | acc: 0.990 - 2395.95s\n",
      " it: 7480 | loss: 0.002 | acc: 1.000 - 2397.98s\n",
      " it: 7490 | loss: 0.003 | acc: 1.000 - 2399.98s\n",
      " it: 7500 | loss: 0.004 | acc: 1.000 - 2402.00s\n",
      " --> test_loss: 0.926 | test_acc: 1.000\n",
      " it: 7510 | loss: 0.002 | acc: 1.000 - 2411.44s\n",
      " it: 7520 | loss: 0.001 | acc: 1.000 - 2414.20s\n",
      " it: 7530 | loss: 0.045 | acc: 0.990 - 2416.18s\n",
      " it: 7540 | loss: 0.004 | acc: 1.000 - 2418.28s\n",
      " it: 7550 | loss: 0.012 | acc: 0.990 - 2420.40s\n",
      " it: 7560 | loss: 0.081 | acc: 0.990 - 2422.86s\n",
      " it: 7570 | loss: 0.007 | acc: 1.000 - 2424.93s\n",
      " it: 7580 | loss: 0.006 | acc: 1.000 - 2426.98s\n",
      " it: 7590 | loss: 0.003 | acc: 1.000 - 2429.11s\n",
      " it: 7600 | loss: 0.011 | acc: 0.990 - 2431.18s\n",
      " --> test_loss: 0.977 | test_acc: 1.000\n",
      " it: 7610 | loss: 0.022 | acc: 0.990 - 2441.64s\n",
      " it: 7620 | loss: 0.003 | acc: 1.000 - 2444.11s\n",
      " it: 7630 | loss: 0.001 | acc: 1.000 - 2446.21s\n",
      " it: 7640 | loss: 0.001 | acc: 1.000 - 2448.24s\n",
      " it: 7650 | loss: 0.033 | acc: 0.990 - 2450.33s\n",
      " it: 7660 | loss: 0.006 | acc: 1.000 - 2452.46s\n",
      " it: 7670 | loss: 0.049 | acc: 0.990 - 2454.52s\n",
      " it: 7680 | loss: 0.002 | acc: 1.000 - 2456.56s\n",
      " it: 7690 | loss: 0.020 | acc: 0.990 - 2458.80s\n",
      " it: 7700 | loss: 0.005 | acc: 1.000 - 2460.89s\n",
      " --> test_loss: 1.216 | test_acc: 1.000\n",
      " it: 7710 | loss: 0.001 | acc: 1.000 - 2471.10s\n",
      " it: 7720 | loss: 0.002 | acc: 1.000 - 2473.77s\n",
      " it: 7730 | loss: 0.001 | acc: 1.000 - 2476.55s\n",
      " it: 7740 | loss: 0.002 | acc: 1.000 - 2479.19s\n",
      " it: 7750 | loss: 0.001 | acc: 1.000 - 2481.94s\n",
      " it: 7760 | loss: 0.001 | acc: 1.000 - 2484.34s\n",
      " it: 7770 | loss: 0.003 | acc: 1.000 - 2487.04s\n",
      " it: 7780 | loss: 0.001 | acc: 1.000 - 2489.64s\n",
      " it: 7790 | loss: 0.001 | acc: 1.000 - 2492.31s\n",
      " it: 7800 | loss: 0.002 | acc: 1.000 - 2494.92s\n",
      " --> test_loss: 1.072 | test_acc: 1.000\n",
      " it: 7810 | loss: 0.001 | acc: 1.000 - 2504.84s\n",
      " it: 7820 | loss: 0.001 | acc: 1.000 - 2506.94s\n",
      " it: 7830 | loss: 0.000 | acc: 1.000 - 2508.92s\n",
      " it: 7840 | loss: 0.001 | acc: 1.000 - 2511.01s\n",
      " it: 7850 | loss: 0.000 | acc: 1.000 - 2513.10s\n",
      " it: 7860 | loss: 0.000 | acc: 1.000 - 2515.41s\n",
      " it: 7870 | loss: 0.005 | acc: 1.000 - 2518.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it: 7880 | loss: 0.000 | acc: 1.000 - 2520.62s\n",
      " it: 7890 | loss: 0.001 | acc: 1.000 - 2523.43s\n",
      " it: 7900 | loss: 0.000 | acc: 1.000 - 2526.04s\n",
      " --> test_loss: 1.062 | test_acc: 1.000\n",
      " it: 7910 | loss: 0.000 | acc: 1.000 - 2538.30s\n",
      " it: 7920 | loss: 0.000 | acc: 1.000 - 2540.87s\n",
      " it: 7930 | loss: 0.000 | acc: 1.000 - 2543.02s\n",
      " it: 7940 | loss: 0.006 | acc: 1.000 - 2545.12s\n",
      " it: 7950 | loss: 0.009 | acc: 0.990 - 2547.23s\n",
      " it: 7960 | loss: 0.001 | acc: 1.000 - 2549.56s\n",
      " it: 7970 | loss: 0.004 | acc: 1.000 - 2552.19s\n",
      " it: 7980 | loss: 0.003 | acc: 1.000 - 2554.56s\n",
      " it: 7990 | loss: 0.001 | acc: 1.000 - 2556.65s\n",
      " it: 8000 | loss: 0.036 | acc: 0.990 - 2558.78s\n",
      " --> test_loss: 0.977 | test_acc: 0.900\n",
      " * model saved at 'models/cnn'\n",
      " it: 8010 | loss: 0.002 | acc: 1.000 - 2569.39s\n",
      " it: 8020 | loss: 0.009 | acc: 0.990 - 2571.50s\n",
      " it: 8030 | loss: 0.001 | acc: 1.000 - 2573.64s\n",
      " it: 8040 | loss: 0.001 | acc: 1.000 - 2575.75s\n",
      " it: 8050 | loss: 0.005 | acc: 1.000 - 2577.91s\n",
      " it: 8060 | loss: 0.001 | acc: 1.000 - 2580.46s\n",
      " it: 8070 | loss: 0.000 | acc: 1.000 - 2583.28s\n",
      " it: 8080 | loss: 0.000 | acc: 1.000 - 2585.95s\n",
      " it: 8090 | loss: 0.001 | acc: 1.000 - 2588.55s\n",
      " it: 8100 | loss: 0.036 | acc: 0.990 - 2590.71s\n",
      " --> test_loss: 1.145 | test_acc: 1.000\n",
      " it: 8110 | loss: 0.022 | acc: 0.990 - 2601.65s\n",
      " it: 8120 | loss: 0.002 | acc: 1.000 - 2603.73s\n",
      " it: 8130 | loss: 0.005 | acc: 1.000 - 2605.85s\n",
      " it: 8140 | loss: 0.012 | acc: 0.990 - 2607.93s\n",
      " it: 8150 | loss: 0.002 | acc: 1.000 - 2610.01s\n",
      " it: 8160 | loss: 0.013 | acc: 0.990 - 2612.10s\n",
      " it: 8170 | loss: 0.003 | acc: 1.000 - 2614.24s\n",
      " it: 8180 | loss: 0.003 | acc: 1.000 - 2616.29s\n",
      " it: 8190 | loss: 0.006 | acc: 1.000 - 2618.39s\n",
      " it: 8200 | loss: 0.001 | acc: 1.000 - 2620.46s\n",
      " --> test_loss: 1.356 | test_acc: 1.000\n",
      " it: 8210 | loss: 0.008 | acc: 0.990 - 2630.18s\n",
      " it: 8220 | loss: 0.000 | acc: 1.000 - 2632.34s\n",
      " it: 8230 | loss: 0.010 | acc: 0.990 - 2634.50s\n",
      " it: 8240 | loss: 0.019 | acc: 0.990 - 2636.60s\n",
      " it: 8250 | loss: 0.054 | acc: 0.980 - 2638.69s\n",
      " it: 8260 | loss: 0.008 | acc: 1.000 - 2640.77s\n",
      " it: 8270 | loss: 0.019 | acc: 0.990 - 2642.89s\n",
      " it: 8280 | loss: 0.001 | acc: 1.000 - 2644.97s\n",
      " it: 8290 | loss: 0.010 | acc: 0.990 - 2647.01s\n",
      " it: 8300 | loss: 0.021 | acc: 0.990 - 2649.13s\n",
      " --> test_loss: 0.986 | test_acc: 1.000\n",
      " it: 8310 | loss: 0.002 | acc: 1.000 - 2660.26s\n",
      " it: 8320 | loss: 0.001 | acc: 1.000 - 2662.76s\n",
      " it: 8330 | loss: 0.007 | acc: 1.000 - 2664.88s\n",
      " it: 8340 | loss: 0.006 | acc: 1.000 - 2666.97s\n",
      " it: 8350 | loss: 0.000 | acc: 1.000 - 2669.11s\n",
      " it: 8360 | loss: 0.002 | acc: 1.000 - 2671.27s\n",
      " it: 8370 | loss: 0.000 | acc: 1.000 - 2673.37s\n",
      " it: 8380 | loss: 0.000 | acc: 1.000 - 2675.45s\n",
      " it: 8390 | loss: 0.000 | acc: 1.000 - 2677.53s\n",
      " it: 8400 | loss: 0.001 | acc: 1.000 - 2679.61s\n",
      " --> test_loss: 0.982 | test_acc: 1.000\n",
      " it: 8410 | loss: 0.000 | acc: 1.000 - 2689.38s\n",
      " it: 8420 | loss: 0.000 | acc: 1.000 - 2691.57s\n",
      " it: 8430 | loss: 0.000 | acc: 1.000 - 2693.71s\n",
      " it: 8440 | loss: 0.000 | acc: 1.000 - 2695.97s\n",
      " it: 8450 | loss: 0.000 | acc: 1.000 - 2698.12s\n",
      " it: 8460 | loss: 0.015 | acc: 0.990 - 2700.29s\n",
      " it: 8470 | loss: 0.000 | acc: 1.000 - 2702.44s\n",
      " it: 8480 | loss: 0.006 | acc: 1.000 - 2704.50s\n",
      " it: 8490 | loss: 0.001 | acc: 1.000 - 2706.60s\n",
      " it: 8500 | loss: 0.001 | acc: 1.000 - 2708.73s\n",
      " --> test_loss: 0.946 | test_acc: 1.000\n",
      " it: 8510 | loss: 0.002 | acc: 1.000 - 2718.56s\n",
      " it: 8520 | loss: 0.001 | acc: 1.000 - 2720.67s\n",
      " it: 8530 | loss: 0.001 | acc: 1.000 - 2722.77s\n",
      " it: 8540 | loss: 0.000 | acc: 1.000 - 2724.90s\n",
      " it: 8550 | loss: 0.001 | acc: 1.000 - 2727.09s\n",
      " it: 8560 | loss: 0.049 | acc: 0.990 - 2729.24s\n",
      " it: 8570 | loss: 0.008 | acc: 1.000 - 2731.33s\n",
      " it: 8580 | loss: 0.043 | acc: 0.990 - 2733.39s\n",
      " it: 8590 | loss: 0.002 | acc: 1.000 - 2735.42s\n",
      " it: 8600 | loss: 0.006 | acc: 1.000 - 2737.54s\n",
      " --> test_loss: 0.971 | test_acc: 1.000\n",
      " it: 8610 | loss: 0.003 | acc: 1.000 - 2747.39s\n",
      " it: 8620 | loss: 0.002 | acc: 1.000 - 2749.47s\n",
      " it: 8630 | loss: 0.001 | acc: 1.000 - 2751.57s\n",
      " it: 8640 | loss: 0.001 | acc: 1.000 - 2753.69s\n",
      " it: 8650 | loss: 0.000 | acc: 1.000 - 2755.79s\n",
      " it: 8660 | loss: 0.000 | acc: 1.000 - 2757.87s\n",
      " it: 8670 | loss: 0.000 | acc: 1.000 - 2760.41s\n",
      " it: 8680 | loss: 0.001 | acc: 1.000 - 2763.05s\n",
      " it: 8690 | loss: 0.000 | acc: 1.000 - 2765.60s\n",
      " it: 8700 | loss: 0.003 | acc: 1.000 - 2768.20s\n",
      " --> test_loss: 0.997 | test_acc: 1.000\n",
      " it: 8710 | loss: 0.000 | acc: 1.000 - 2778.33s\n",
      " it: 8720 | loss: 0.001 | acc: 1.000 - 2780.44s\n",
      " it: 8730 | loss: 0.001 | acc: 1.000 - 2782.53s\n",
      " it: 8740 | loss: 0.000 | acc: 1.000 - 2784.71s\n",
      " it: 8750 | loss: 0.001 | acc: 1.000 - 2786.82s\n",
      " it: 8760 | loss: 0.001 | acc: 1.000 - 2789.07s\n",
      " it: 8770 | loss: 0.001 | acc: 1.000 - 2791.79s\n",
      " it: 8780 | loss: 0.001 | acc: 1.000 - 2794.45s\n",
      " it: 8790 | loss: 0.000 | acc: 1.000 - 2797.18s\n",
      " it: 8800 | loss: 0.000 | acc: 1.000 - 2799.88s\n",
      " --> test_loss: 1.292 | test_acc: 1.000\n",
      " it: 8810 | loss: 0.001 | acc: 1.000 - 2811.31s\n",
      " it: 8820 | loss: 0.000 | acc: 1.000 - 2813.42s\n",
      " it: 8830 | loss: 0.000 | acc: 1.000 - 2815.59s\n",
      " it: 8840 | loss: 0.014 | acc: 0.990 - 2817.72s\n",
      " it: 8850 | loss: 0.006 | acc: 1.000 - 2819.82s\n",
      " it: 8860 | loss: 0.000 | acc: 1.000 - 2822.03s\n",
      " it: 8870 | loss: 0.008 | acc: 1.000 - 2824.09s\n",
      " it: 8880 | loss: 0.001 | acc: 1.000 - 2826.21s\n",
      " it: 8890 | loss: 0.116 | acc: 0.990 - 2828.33s\n",
      " it: 8900 | loss: 0.005 | acc: 1.000 - 2830.51s\n",
      " --> test_loss: 0.965 | test_acc: 1.000\n",
      " it: 8910 | loss: 0.003 | acc: 1.000 - 2841.63s\n",
      " it: 8920 | loss: 0.043 | acc: 0.980 - 2844.23s\n",
      " it: 8930 | loss: 0.017 | acc: 1.000 - 2846.37s\n",
      " it: 8940 | loss: 0.008 | acc: 1.000 - 2848.52s\n",
      " it: 8950 | loss: 0.055 | acc: 0.980 - 2850.74s\n",
      " it: 8960 | loss: 0.064 | acc: 0.980 - 2853.34s\n",
      " it: 8970 | loss: 0.006 | acc: 1.000 - 2855.55s\n",
      " it: 8980 | loss: 0.025 | acc: 0.990 - 2857.64s\n",
      " it: 8990 | loss: 0.004 | acc: 1.000 - 2859.78s\n",
      " it: 9000 | loss: 0.004 | acc: 1.000 - 2861.91s\n",
      " --> test_loss: 0.944 | test_acc: 1.000\n",
      " * model saved at 'models/cnn'\n",
      " it: 9010 | loss: 0.034 | acc: 0.990 - 2873.98s\n",
      " it: 9020 | loss: 0.006 | acc: 1.000 - 2876.78s\n",
      " it: 9030 | loss: 0.005 | acc: 1.000 - 2879.44s\n",
      " it: 9040 | loss: 0.003 | acc: 1.000 - 2881.91s\n",
      " it: 9050 | loss: 0.024 | acc: 0.990 - 2884.04s\n",
      " it: 9060 | loss: 0.001 | acc: 1.000 - 2886.21s\n",
      " it: 9070 | loss: 0.004 | acc: 1.000 - 2888.34s\n",
      " it: 9080 | loss: 0.001 | acc: 1.000 - 2890.44s\n",
      " it: 9090 | loss: 0.003 | acc: 1.000 - 2892.56s\n",
      " it: 9100 | loss: 0.010 | acc: 0.990 - 2894.69s\n",
      " --> test_loss: 0.777 | test_acc: 1.000\n",
      " it: 9110 | loss: 0.043 | acc: 0.990 - 2906.38s\n",
      " it: 9120 | loss: 0.002 | acc: 1.000 - 2908.47s\n",
      " it: 9130 | loss: 0.031 | acc: 0.990 - 2910.60s\n",
      " it: 9140 | loss: 0.007 | acc: 1.000 - 2912.87s\n",
      " it: 9150 | loss: 0.004 | acc: 1.000 - 2915.00s\n",
      " it: 9160 | loss: 0.002 | acc: 1.000 - 2917.12s\n",
      " it: 9170 | loss: 0.010 | acc: 0.990 - 2919.26s\n",
      " it: 9180 | loss: 0.001 | acc: 1.000 - 2921.39s\n",
      " it: 9190 | loss: 0.001 | acc: 1.000 - 2923.52s\n",
      " it: 9200 | loss: 0.007 | acc: 1.000 - 2925.73s\n",
      " --> test_loss: 1.011 | test_acc: 1.000\n",
      " it: 9210 | loss: 0.037 | acc: 0.990 - 2935.67s\n",
      " it: 9220 | loss: 0.010 | acc: 0.990 - 2938.03s\n",
      " it: 9230 | loss: 0.001 | acc: 1.000 - 2940.17s\n",
      " it: 9240 | loss: 0.060 | acc: 0.990 - 2942.73s\n",
      " it: 9250 | loss: 0.002 | acc: 1.000 - 2945.02s\n",
      " it: 9260 | loss: 0.002 | acc: 1.000 - 2947.09s\n",
      " it: 9270 | loss: 0.004 | acc: 1.000 - 2949.22s\n",
      " it: 9280 | loss: 0.079 | acc: 0.990 - 2951.39s\n",
      " it: 9290 | loss: 0.005 | acc: 1.000 - 2953.57s\n",
      " it: 9300 | loss: 0.006 | acc: 1.000 - 2955.81s\n",
      " --> test_loss: 0.811 | test_acc: 1.000\n",
      " it: 9310 | loss: 0.027 | acc: 0.990 - 2966.63s\n",
      " it: 9320 | loss: 0.002 | acc: 1.000 - 2968.75s\n",
      " it: 9330 | loss: 0.003 | acc: 1.000 - 2971.01s\n",
      " it: 9340 | loss: 0.002 | acc: 1.000 - 2973.71s\n",
      " it: 9350 | loss: 0.002 | acc: 1.000 - 2975.86s\n",
      " it: 9360 | loss: 0.066 | acc: 0.990 - 2978.00s\n",
      " it: 9370 | loss: 0.004 | acc: 1.000 - 2980.12s\n",
      " it: 9380 | loss: 0.005 | acc: 1.000 - 2982.25s\n",
      " it: 9390 | loss: 0.006 | acc: 1.000 - 2984.37s\n",
      " it: 9400 | loss: 0.001 | acc: 1.000 - 2986.55s\n",
      " --> test_loss: 0.734 | test_acc: 1.000\n",
      " it: 9410 | loss: 0.007 | acc: 1.000 - 2996.42s\n",
      " it: 9420 | loss: 0.010 | acc: 0.990 - 2998.55s\n",
      " it: 9430 | loss: 0.012 | acc: 0.990 - 3000.66s\n",
      " it: 9440 | loss: 0.010 | acc: 0.990 - 3002.80s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it: 9450 | loss: 0.000 | acc: 1.000 - 3005.01s\n",
      " it: 9460 | loss: 0.001 | acc: 1.000 - 3007.10s\n",
      " it: 9470 | loss: 0.001 | acc: 1.000 - 3009.16s\n",
      " it: 9480 | loss: 0.001 | acc: 1.000 - 3011.28s\n",
      " it: 9490 | loss: 0.001 | acc: 1.000 - 3013.82s\n",
      " it: 9500 | loss: 0.001 | acc: 1.000 - 3016.21s\n",
      " --> test_loss: 0.950 | test_acc: 1.000\n",
      " it: 9510 | loss: 0.009 | acc: 1.000 - 3026.12s\n",
      " it: 9520 | loss: 0.000 | acc: 1.000 - 3028.28s\n",
      " it: 9530 | loss: 0.001 | acc: 1.000 - 3030.40s\n",
      " it: 9540 | loss: 0.001 | acc: 1.000 - 3032.56s\n",
      " it: 9550 | loss: 0.001 | acc: 1.000 - 3034.65s\n",
      " it: 9560 | loss: 0.001 | acc: 1.000 - 3036.79s\n",
      " it: 9570 | loss: 0.001 | acc: 1.000 - 3038.90s\n",
      " it: 9580 | loss: 0.002 | acc: 1.000 - 3041.06s\n",
      " it: 9590 | loss: 0.009 | acc: 1.000 - 3043.14s\n",
      " it: 9600 | loss: 0.002 | acc: 1.000 - 3045.23s\n",
      " --> test_loss: 1.096 | test_acc: 1.000\n",
      " it: 9610 | loss: 0.032 | acc: 0.990 - 3055.15s\n",
      " it: 9620 | loss: 0.001 | acc: 1.000 - 3057.27s\n",
      " it: 9630 | loss: 0.002 | acc: 1.000 - 3059.39s\n",
      " it: 9640 | loss: 0.005 | acc: 1.000 - 3061.53s\n",
      " it: 9650 | loss: 0.001 | acc: 1.000 - 3063.66s\n",
      " it: 9660 | loss: 0.013 | acc: 0.990 - 3065.87s\n",
      " it: 9670 | loss: 0.003 | acc: 1.000 - 3068.04s\n",
      " it: 9680 | loss: 0.077 | acc: 0.990 - 3070.17s\n",
      " it: 9690 | loss: 0.004 | acc: 1.000 - 3072.32s\n",
      " it: 9700 | loss: 0.001 | acc: 1.000 - 3074.48s\n",
      " --> test_loss: 0.966 | test_acc: 1.000\n",
      " it: 9710 | loss: 0.001 | acc: 1.000 - 3086.46s\n",
      " it: 9720 | loss: 0.001 | acc: 1.000 - 3088.54s\n",
      " it: 9730 | loss: 0.001 | acc: 1.000 - 3090.73s\n",
      " it: 9740 | loss: 0.000 | acc: 1.000 - 3092.85s\n",
      " it: 9750 | loss: 0.002 | acc: 1.000 - 3094.95s\n",
      " it: 9760 | loss: 0.001 | acc: 1.000 - 3097.12s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from rnn_model import Model\n",
    "from imdb_loader import text_data\n",
    "\n",
    "def initialize_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "##################################################\n",
    "max_len = 200           # sequence   \n",
    "max_vocab = 20000       # maximum  \n",
    "BATCH_SIZE = 10         #  \n",
    "emb_dim = 64            #  embedding dimension\n",
    "hidden_dim = 128        # RNN hidden dim\n",
    "learning_rate = 0.0025  # Learning rate\n",
    "use_clip = True         # Gradient clipping  \n",
    "##################################################\n",
    "\n",
    "END_TOKEN = \"<eos>\"\n",
    "data = text_data(\"./dataset/aclImdb/\", max_len=max_len, end_token=END_TOKEN)\n",
    "model = Model(max_len=max_len,\n",
    "              emb_dim=emb_dim,\n",
    "              hidden_dim=hidden_dim,\n",
    "              vocab_size=data.vocab_size,\n",
    "              class_size=2,\n",
    "              use_clip=True, learning_rate=learning_rate, end_token=data.w2idx[END_TOKEN])\n",
    "\n",
    "sess = initialize_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def test_model():\n",
    "    num_it = int(len(data.test_ids) / BATCH_SIZE)\n",
    "    num_it = 100\n",
    "    same, test_loss, test_cnt = .0, 0, 0\n",
    "\n",
    "    for _ in range(num_it):\n",
    "        test_ids, length, label = data.get_test(BATCH_SIZE)\n",
    "        loss = sess.run(model.loss, feed_dict={model.x: test_ids, model.x_len: length, model.y: label})\n",
    "\n",
    "        for i, o in enumerate(out):\n",
    "            if o == label[i]:\n",
    "                same += 1\n",
    "        test_loss += loss\n",
    "        test_cnt += 1\n",
    "    print(\" --> test_loss: {:.3f} | test_acc: {:.3f}\".format(test_loss / test_cnt, same/test_cnt/BATCH_SIZE))\n",
    "\n",
    "# 0: neg, 1: pos\n",
    "avg_loss, it_cnt, same = 0, 0, .0\n",
    "it_log, it_test, it_save, it_sample = 10, 100, 1000, 100\n",
    "start_time = time.time()\n",
    "\n",
    "for it in range(0, 10000):\n",
    "    train_ids, length, label = data.get_train(BATCH_SIZE)\n",
    "    loss, _, out = sess.run([model.loss, model.update, model.out_label],\n",
    "                            feed_dict={model.x: train_ids, model.x_len: length, model.y: label, model.keep_prob: 0.5})\n",
    "    for i, o in enumerate(out):\n",
    "        if o == label[i]:\n",
    "            same += 1\n",
    "    avg_loss += loss\n",
    "    it_cnt += 1\n",
    "\n",
    "    if it % it_log == 0 and it:\n",
    "        print(\" it: {:4d} | loss: {:.3f} | acc: {:.3f} - {:.2f}s\".format(\n",
    "            it, avg_loss / it_cnt, same/BATCH_SIZE/it_log, time.time() - start_time))\n",
    "        avg_loss, it_cnt, same = 0, 0, .0\n",
    "\n",
    "    if it % it_test == 0 and it > 0:\n",
    "        test_model()\n",
    "    if it % it_save == 0 and it > 0:\n",
    "        model.save(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
