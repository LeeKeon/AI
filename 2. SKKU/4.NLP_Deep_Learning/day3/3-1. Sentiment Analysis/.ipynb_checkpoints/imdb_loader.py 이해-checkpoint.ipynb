{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "w2idx = {\"<eos>\": 0, \"<unk>\": 1}\n",
    "max_vocab = 20000\n",
    "max_len = 100\n",
    "\n",
    "def get_w2idx(word):\n",
    "    return 1 if word not in w2idx else w2idx[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_ids(path):\n",
    "        pos_list = os.listdir(path + \"/pos\")\n",
    "        neg_list = os.listdir(path + \"/neg\")\n",
    "\n",
    "        size = len(pos_list)\n",
    "        lines = []\n",
    "        for i in range(size):\n",
    "            with open(path + \"/neg/\" + neg_list[i], \"r\", encoding=\"utf-8\") as fin:\n",
    "                lines.append(fin.readline())\n",
    "            with open(path + \"/pos/\" + pos_list[i], \"r\", encoding=\"utf-8\") as fin:\n",
    "                lines.append(fin.readline())\n",
    "\n",
    "        if \"train\" in path:\n",
    "            #많이 사용하는 단어대로만 사용\n",
    "            cnt = {}\n",
    "            for line in lines:\n",
    "                for word in line.split():\n",
    "                    if word in cnt:\n",
    "                        cnt[word] += 1\n",
    "                    else:\n",
    "                        cnt[word] = 1\n",
    "            cnt_sort = sorted(cnt.items(), key=lambda cnt:cnt[1], reverse=True)\n",
    "            for word, count in cnt_sort:\n",
    "                w2idx[word] = len(w2idx)\n",
    "                if w2idx == max_vocab:\n",
    "                    break\n",
    "\n",
    "        length, ids, label = [], [], []\n",
    "        for num, line in enumerate(lines):\n",
    "            id = np.zeros(max_len, dtype=np.int32)\n",
    "            line += \" <eos>\"\n",
    "            words = line.split()\n",
    "            for i, word in enumerate(words):\n",
    "                if i == max_len:\n",
    "                    break\n",
    "                if word not in w2idx and len(w2idx) < max_vocab:\n",
    "                    w2idx[word] = len(w2idx)\n",
    "                id[i] = get_w2idx(word)\n",
    "            ids.append(id)\n",
    "            length.append(i)\n",
    "            label.append(num % 2)\n",
    "\n",
    "        return np.array(ids), np.array(length), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/aclImdb/'\n",
    "train_ids, train_len, train_label = files_to_ids(path + \"train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_data(object):\n",
    "    def __init__(self, path=\"./dataset/aclImdb/\", max_vocab=20000, max_len=100, end_token=\"<eos>\"):\n",
    "        self.train_pt, self.val_pt, self.test_pt = 0, 0, 0\n",
    "        self.path = path\n",
    "        self.max_len = max_len\n",
    "        self.max_vocab = max_vocab\n",
    "\n",
    "        self.w2idx = {end_token: 0, \"<unk>\": 1}\n",
    "        self.train_ids, self.train_len, self.train_label = self.files_to_ids(path + \"train/\")\n",
    "        self.test_ids, self.test_len, self.test_label = self.files_to_ids(path + \"test/\")\n",
    "        self.vocab_size = len(self.w2idx)\n",
    "\n",
    "        self.train_size = len(self.train_ids)\n",
    "        self.test_size = len(self.test_ids)\n",
    "\n",
    "        self.idx2w = {}\n",
    "        for word in self.w2idx:\n",
    "            self.idx2w[self.w2idx[word]] = word\n",
    "\n",
    "    def get_w2idx(self, word):\n",
    "        return 1 if word not in self.w2idx else self.w2idx[word]\n",
    "\n",
    "    def files_to_ids(self, path):\n",
    "        pos_list = os.listdir(path + \"/pos\")\n",
    "        neg_list = os.listdir(path + \"/neg\")\n",
    "\n",
    "        size = len(pos_list)\n",
    "        lines = []\n",
    "        for i in range(size):\n",
    "            with open(path + \"/neg/\" + neg_list[i], \"r\", encoding=\"utf-8\") as fin:\n",
    "                lines.append(fin.readline())\n",
    "            with open(path + \"/pos/\" + pos_list[i], \"r\", encoding=\"utf-8\") as fin:\n",
    "                lines.append(fin.readline())\n",
    "\n",
    "        if \"train\" in path:\n",
    "            cnt = {}\n",
    "            for line in lines:\n",
    "                for word in line.split():\n",
    "                    if word in cnt:\n",
    "                        cnt[word] += 1\n",
    "                    else:\n",
    "                        cnt[word] = 1\n",
    "            cnt_sort = sorted(cnt.items(), key=lambda cnt:cnt[1], reverse=True)\n",
    "            for word, count in cnt_sort:\n",
    "                self.w2idx[word] = len(self.w2idx)\n",
    "                if self.w2idx == self.max_vocab:\n",
    "                    break\n",
    "\n",
    "        length, ids, label = [], [], []\n",
    "        for num, line in enumerate(lines):\n",
    "            id = np.zeros(self.max_len, dtype=np.int32)\n",
    "            line += \" <eos>\"\n",
    "            words = line.split()\n",
    "            for i, word in enumerate(words):\n",
    "                if i == self.max_len:\n",
    "                    break\n",
    "                if word not in self.w2idx and len(self.w2idx) < self.max_vocab:\n",
    "                    self.w2idx[word] = len(self.w2idx)\n",
    "                id[i] = self.get_w2idx(word)\n",
    "            ids.append(id)\n",
    "            length.append(i)\n",
    "            label.append(num % 2)\n",
    "\n",
    "        return np.array(ids), np.array(length), np.array(label)\n",
    "\n",
    "    def get_train(self, batch_size=20):\n",
    "        pt = self.train_pt\n",
    "        self.train_pt = (self.train_pt + batch_size) % self.train_size\n",
    "        return self.train_ids[pt: pt+batch_size], self.train_len[pt: pt+batch_size], self.train_label[pt: pt+batch_size]\n",
    "\n",
    "    def get_test(self, batch_size=20):\n",
    "        pt = self.test_pt\n",
    "        self.test_pt = (self.test_pt + batch_size) % self.test_size\n",
    "        return self.test_ids[pt: pt+batch_size], self.test_len[pt: pt+batch_size], self.test_label[pt: pt+batch_size]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
