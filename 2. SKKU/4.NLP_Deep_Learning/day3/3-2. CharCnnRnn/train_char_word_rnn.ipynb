{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(?, 29, 15, 64), dtype=float32)\n",
      "Tensor(\"embedding_lookup_1:0\", shape=(?, 29, 64), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 15, 64, 1), dtype=float32)\n",
      " it:    0 | loss: 6.318 - 0.92s\n",
      " it:   10 | loss: 6.035 - 1.18s\n",
      " it:   20 | loss: 5.265 - 1.39s\n",
      " it:   30 | loss: 4.922 - 1.59s\n",
      " it:   40 | loss: 4.857 - 1.80s\n",
      " it:   50 | loss: 4.815 - 2.00s\n",
      " it:   60 | loss: 4.785 - 2.21s\n",
      " it:   70 | loss: 4.748 - 2.45s\n",
      " it:   80 | loss: 4.709 - 2.66s\n",
      " it:   90 | loss: 4.670 - 2.91s\n",
      " it:  100 | loss: 4.629 - 3.13s\n",
      "test loss: 8.140\n",
      " it:  110 | loss: 4.587 - 3.51s\n",
      " it:  120 | loss: 4.546 - 3.76s\n",
      " it:  130 | loss: 4.508 - 4.00s\n",
      " it:  140 | loss: 4.474 - 4.23s\n",
      " it:  150 | loss: 4.434 - 4.52s\n",
      " it:  160 | loss: 4.396 - 4.79s\n",
      " it:  170 | loss: 4.359 - 5.03s\n",
      " it:  180 | loss: 4.323 - 5.32s\n",
      " it:  190 | loss: 4.288 - 5.57s\n",
      " it:  200 | loss: 4.254 - 5.87s\n",
      "test loss: 8.719\n",
      " it:  210 | loss: 4.220 - 6.25s\n",
      " it:  220 | loss: 4.182 - 6.49s\n",
      " it:  230 | loss: 4.141 - 6.73s\n",
      " it:  240 | loss: 4.101 - 6.99s\n",
      " it:  250 | loss: 4.051 - 7.30s\n",
      " it:  260 | loss: 4.004 - 7.64s\n",
      " it:  270 | loss: 3.960 - 7.87s\n",
      " it:  280 | loss: 3.912 - 8.16s\n",
      " it:  290 | loss: 3.853 - 8.42s\n",
      " it:  300 | loss: 3.796 - 8.72s\n",
      "test loss: 8.891\n",
      " it:  310 | loss: 3.737 - 9.03s\n",
      " it:  320 | loss: 3.688 - 9.29s\n",
      " it:  330 | loss: 3.629 - 9.64s\n",
      " it:  340 | loss: 3.563 - 9.97s\n",
      " it:  350 | loss: 3.503 - 10.22s\n",
      " it:  360 | loss: 3.424 - 10.50s\n",
      " it:  370 | loss: 3.355 - 10.77s\n",
      " it:  380 | loss: 3.284 - 11.01s\n",
      " it:  390 | loss: 3.213 - 11.21s\n",
      " it:  400 | loss: 3.140 - 11.45s\n",
      "test loss: 8.995\n",
      " it:  410 | loss: 3.069 - 11.75s\n",
      " it:  420 | loss: 3.005 - 11.99s\n",
      " it:  430 | loss: 2.929 - 12.22s\n",
      " it:  440 | loss: 2.854 - 12.49s\n",
      " it:  450 | loss: 2.784 - 12.69s\n",
      " it:  460 | loss: 2.715 - 12.93s\n",
      " it:  470 | loss: 2.633 - 13.16s\n",
      " it:  480 | loss: 2.553 - 13.39s\n",
      " it:  490 | loss: 2.476 - 13.63s\n",
      " it:  500 | loss: 2.397 - 13.88s\n",
      "test loss: 9.053\n",
      " it:  510 | loss: 2.317 - 14.24s\n",
      " it:  520 | loss: 2.234 - 14.56s\n",
      " it:  530 | loss: 2.149 - 14.87s\n",
      " it:  540 | loss: 2.068 - 15.10s\n",
      " it:  550 | loss: 1.986 - 15.32s\n",
      " it:  560 | loss: 1.907 - 15.56s\n",
      " it:  570 | loss: 1.829 - 15.78s\n",
      " it:  580 | loss: 1.753 - 16.00s\n",
      " it:  590 | loss: 1.678 - 16.21s\n",
      " it:  600 | loss: 1.604 - 16.42s\n",
      "test loss: 9.288\n",
      " it:  610 | loss: 1.533 - 16.72s\n",
      " it:  620 | loss: 1.465 - 16.95s\n",
      " it:  630 | loss: 1.399 - 17.21s\n",
      " it:  640 | loss: 1.334 - 17.43s\n",
      " it:  650 | loss: 1.271 - 17.71s\n",
      " it:  660 | loss: 1.211 - 17.98s\n",
      " it:  670 | loss: 1.157 - 18.22s\n",
      " it:  680 | loss: 1.106 - 18.48s\n",
      " it:  690 | loss: 1.067 - 18.71s\n",
      " it:  700 | loss: 1.003 - 18.95s\n",
      "test loss: 9.550\n",
      " it:  710 | loss: 0.953 - 19.31s\n",
      " it:  720 | loss: 0.907 - 19.55s\n",
      " it:  730 | loss: 0.863 - 19.77s\n",
      " it:  740 | loss: 0.822 - 20.02s\n",
      " it:  750 | loss: 0.782 - 20.29s\n",
      " it:  760 | loss: 0.745 - 20.52s\n",
      " it:  770 | loss: 0.710 - 20.73s\n",
      " it:  780 | loss: 0.677 - 20.94s\n",
      " it:  790 | loss: 0.648 - 21.18s\n",
      " it:  800 | loss: 0.618 - 21.45s\n",
      "test loss: 9.738\n",
      " it:  810 | loss: 0.588 - 21.76s\n",
      " it:  820 | loss: 0.562 - 21.97s\n",
      " it:  830 | loss: 0.537 - 22.23s\n",
      " it:  840 | loss: 0.513 - 22.49s\n",
      " it:  850 | loss: 0.491 - 22.80s\n",
      " it:  860 | loss: 0.470 - 23.04s\n",
      " it:  870 | loss: 0.450 - 23.30s\n",
      " it:  880 | loss: 0.432 - 23.54s\n",
      " it:  890 | loss: 0.414 - 23.76s\n",
      " it:  900 | loss: 0.398 - 23.98s\n",
      "test loss: 9.903\n",
      " it:  910 | loss: 0.382 - 24.30s\n",
      " it:  920 | loss: 0.367 - 24.58s\n",
      " it:  930 | loss: 0.353 - 24.84s\n",
      " it:  940 | loss: 0.340 - 25.06s\n",
      " it:  950 | loss: 0.328 - 25.28s\n",
      " it:  960 | loss: 0.316 - 25.51s\n",
      " it:  970 | loss: 0.305 - 25.75s\n",
      " it:  980 | loss: 0.294 - 25.95s\n",
      " it:  990 | loss: 0.283 - 26.22s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from charCnn_rnn_model import Model\n",
    "from data_loader_char import text_data\n",
    "\n",
    "def initialize_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "##################################################\n",
    "max_seq_len = 30       # sequence 단어 수 제한\n",
    "max_word_len = 15      # 단어의 최대 길이\n",
    "\n",
    "BATCH_SIZE = 10         # 배치 사이즈\n",
    "emb_dim = 64            # 단어 embedding dimension\n",
    "rnn_hidden_dim = 128    # RNN hidden dim\n",
    "\n",
    "filter_sizes = [2, 3, 4]    # CNN filter size\n",
    "filter_nums = [100, 100, 100]  # # of CNN filter\n",
    "\n",
    "learning_rate = 0.001  # Learning rate\n",
    "use_clip = True        # Gradient clipping 쓸지 여부\n",
    "##################################################\n",
    "\n",
    "END_TOKEN = \"<eos>\"\n",
    "data = text_data(\"./dataset/ptb\", max_seq_len=max_seq_len, max_word_len=max_word_len, end_token=END_TOKEN)\n",
    "model = Model(max_seq_len=max_seq_len, max_word_len=max_word_len,\n",
    "              emb_dim=emb_dim, rnn_hidden_dim=rnn_hidden_dim,\n",
    "              filter_sizes=filter_sizes, filter_nums=filter_nums,\n",
    "              vocab_size=data.vocab_size, char_size=data.char_size,\n",
    "              use_clip=True, learning_rate=learning_rate)\n",
    "\n",
    "sess = initialize_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "def sample_test(test_input=\"\"):\n",
    "    # test_input = raw_input(\"test text: \") # input(\"test text: \") for python 2, 3\n",
    "    words = test_input.split()\n",
    "    x_word = np.zeros((1, max_seq_len), dtype=np.int32)\n",
    "    x_char = np.zeros((1, max_seq_len, max_word_len), dtype=np.int32)\n",
    "\n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        if i == max_seq_len:\n",
    "            break\n",
    "        x_word[0][i] = data.w2idx[word]\n",
    "\n",
    "        for j, w in enumerate(word):\n",
    "            if j == max_word_len:\n",
    "                break\n",
    "            x_char[0][i][j] = data.c2idx[w]\n",
    "\n",
    "    output = sess.run(model.output,\n",
    "                      feed_dict={model.x_word: x_word, model.x_char: x_char, model.x_len: [i+1]})\n",
    "    print(\"{} --> {} (answer: {})\".format(words[:-1], data.idx2w[output[0][i]], words[-1]))\n",
    "    print()\n",
    "\n",
    "def test_model():\n",
    "    num_it = int(len(data.test_ids) / BATCH_SIZE)\n",
    "    num_it = 10\n",
    "    test_loss, test_cnt = 0, 0\n",
    "\n",
    "    for _ in range(num_it):\n",
    "        test_ids, test_chars, length = data.get_test(BATCH_SIZE)\n",
    "        loss = sess.run(model.loss, feed_dict={model.x_word: test_ids, model.x_char: test_chars, model.x_len: length})\n",
    "\n",
    "        test_loss += loss\n",
    "        test_cnt += 1\n",
    "        \n",
    "    print(\"test loss: {:.3f}\".format(test_loss / test_cnt))\n",
    "\n",
    "avg_loss, it_cnt = 0, 0\n",
    "it_log, it_test, it_save, it_sample = 10, 100, 1000, 100\n",
    "start_time = time.time()\n",
    "\n",
    "for it in range(0, 1000):\n",
    "    train_ids, train_chars, length = data.get_train(BATCH_SIZE)\n",
    "    loss, _ = sess.run([model.loss, model.update],\n",
    "                       feed_dict={model.x_word: train_ids, model.x_char: train_chars, model.x_len: length})\n",
    "\n",
    "    avg_loss += loss\n",
    "    it_cnt += 1\n",
    "\n",
    "    if it % it_log == 0:\n",
    "        print(\" it: {:4d} | loss: {:.3f} - {:.2f}s\".format(it, avg_loss / it_cnt, time.time() - start_time))\n",
    "        avg_loss, it_cnt = 0, 0\n",
    "\n",
    "    if it % it_test == 0 and it > 0:\n",
    "        test_model()\n",
    "    if it % it_save == 0 and it > 0:\n",
    "        model.save(sess)\n",
    "    #if it % it_sample == 0 and it > 0:\n",
    "        #sample_test(\"we 're talking about years ago before \")\n",
    "\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(data.train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
