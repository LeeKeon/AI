{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it:    0 | loss: 8.859 - 0.37s\n",
      "test loss: 8.823\n",
      " it:   50 | loss: 7.054 - 29.86s\n",
      " it:  100 | loss: 6.849 - 32.48s\n",
      " it:  150 | loss: 7.030 - 35.34s\n",
      " it:  200 | loss: 6.879 - 38.48s\n",
      " it:  250 | loss: 6.679 - 41.36s\n",
      "test loss: 6.662\n",
      "27 N\n",
      " it:  300 | loss: 6.463 - 69.50s\n",
      " it:  350 | loss: 6.772 - 72.59s\n",
      " it:  400 | loss: 6.661 - 75.95s\n",
      " it:  450 | loss: 6.458 - 79.08s\n",
      " it:  500 | loss: 6.612 - 82.47s\n",
      "test loss: 6.262\n",
      "873 take\n",
      " it:  550 | loss: 6.602 - 110.75s\n",
      " it:  600 | loss: 6.244 - 114.07s\n",
      " it:  650 | loss: 6.162 - 117.02s\n",
      " it:  700 | loss: 5.749 - 120.14s\n",
      " it:  750 | loss: 6.434 - 122.80s\n",
      "test loss: 6.079\n",
      "32 the\n",
      " it:  800 | loss: 6.427 - 144.45s\n",
      " it:  850 | loss: 6.231 - 146.30s\n",
      " it:  900 | loss: 6.280 - 148.10s\n",
      " it:  950 | loss: 6.405 - 150.02s\n",
      " it: 1000 | loss: 6.290 - 151.98s\n",
      "test loss: 6.042\n",
      "WARNING:tensorflow:From /home/frank/4.NLP_Deep_Learning/day1/1-3-1. DNN/dnn_model.py:72: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      " * model saved at 'models/dnn'\n",
      "32 the\n",
      " it: 1050 | loss: 5.410 - 166.86s\n",
      " it: 1100 | loss: 5.591 - 168.65s\n",
      " it: 1150 | loss: 5.871 - 170.40s\n",
      " it: 1200 | loss: 5.815 - 172.29s\n",
      " it: 1250 | loss: 5.673 - 174.18s\n",
      "test loss: 5.950\n",
      "26 <unk>\n",
      " it: 1300 | loss: 5.568 - 189.13s\n",
      " it: 1350 | loss: 5.782 - 191.03s\n",
      " it: 1400 | loss: 5.695 - 192.99s\n",
      " it: 1450 | loss: 5.559 - 194.87s\n",
      " it: 1500 | loss: 5.779 - 196.99s\n",
      "test loss: 5.907\n",
      "873 take\n",
      " it: 1550 | loss: 5.884 - 212.13s\n",
      " it: 1600 | loss: 5.390 - 214.01s\n",
      " it: 1650 | loss: 5.441 - 215.85s\n",
      " it: 1700 | loss: 5.126 - 217.77s\n",
      " it: 1750 | loss: 5.712 - 219.36s\n",
      "test loss: 5.855\n",
      "32 the\n",
      " it: 1800 | loss: 5.758 - 234.89s\n",
      " it: 1850 | loss: 5.514 - 236.70s\n",
      " it: 1900 | loss: 5.607 - 238.50s\n",
      " it: 1950 | loss: 5.823 - 240.32s\n",
      " it: 2000 | loss: 5.664 - 242.31s\n",
      "test loss: 5.820\n",
      " * model saved at 'models/dnn'\n",
      "32 the\n",
      " it: 2050 | loss: 5.108 - 257.14s\n",
      " it: 2100 | loss: 5.258 - 258.89s\n",
      " it: 2150 | loss: 5.641 - 260.67s\n",
      " it: 2200 | loss: 5.473 - 262.64s\n",
      " it: 2250 | loss: 5.263 - 264.53s\n",
      "test loss: 5.874\n",
      "26 <unk>\n",
      " it: 2300 | loss: 5.154 - 279.59s\n",
      " it: 2350 | loss: 5.396 - 281.46s\n",
      " it: 2400 | loss: 5.263 - 283.40s\n",
      " it: 2450 | loss: 5.145 - 285.20s\n",
      " it: 2500 | loss: 5.386 - 287.22s\n",
      "test loss: 5.505\n",
      "873 take\n",
      " it: 2550 | loss: 5.484 - 301.88s\n",
      " it: 2600 | loss: 4.936 - 303.76s\n",
      " it: 2650 | loss: 5.035 - 305.58s\n",
      " it: 2700 | loss: 4.727 - 307.46s\n",
      " it: 2750 | loss: 5.314 - 309.08s\n",
      "test loss: 5.486\n",
      "26 <unk>\n",
      " it: 2800 | loss: 5.385 - 323.90s\n",
      " it: 2850 | loss: 5.109 - 325.72s\n",
      " it: 2900 | loss: 5.150 - 327.51s\n",
      " it: 2950 | loss: 5.465 - 329.44s\n",
      " it: 3000 | loss: 5.272 - 331.47s\n",
      "test loss: 5.455\n",
      " * model saved at 'models/dnn'\n",
      "32 the\n",
      " it: 3050 | loss: 4.930 - 346.18s\n",
      " it: 3100 | loss: 5.043 - 347.94s\n",
      " it: 3150 | loss: 5.389 - 349.68s\n",
      " it: 3200 | loss: 5.141 - 351.55s\n",
      " it: 3250 | loss: 4.954 - 353.33s\n",
      "test loss: 5.599\n",
      "26 <unk>\n",
      " it: 3300 | loss: 4.862 - 367.88s\n",
      " it: 3350 | loss: 5.121 - 369.77s\n",
      " it: 3400 | loss: 5.032 - 371.76s\n",
      " it: 3450 | loss: 4.876 - 373.53s\n",
      " it: 3500 | loss: 5.136 - 375.59s\n",
      "test loss: 5.158\n",
      "873 take\n",
      " it: 3550 | loss: 5.141 - 391.30s\n",
      " it: 3600 | loss: 4.614 - 393.28s\n",
      " it: 3650 | loss: 4.769 - 395.22s\n",
      " it: 3700 | loss: 4.455 - 397.22s\n",
      " it: 3750 | loss: 4.977 - 398.93s\n",
      "test loss: 5.156\n",
      "26 <unk>\n",
      " it: 3800 | loss: 5.065 - 415.04s\n",
      " it: 3850 | loss: 4.833 - 416.92s\n",
      " it: 3900 | loss: 4.914 - 418.80s\n",
      " it: 3950 | loss: 5.127 - 420.79s\n",
      " it: 4000 | loss: 4.844 - 422.93s\n",
      "test loss: 5.042\n",
      " * model saved at 'models/dnn'\n",
      "32 the\n",
      " it: 4050 | loss: 4.652 - 439.46s\n",
      " it: 4100 | loss: 4.683 - 441.27s\n",
      " it: 4150 | loss: 5.114 - 443.13s\n",
      " it: 4200 | loss: 4.850 - 445.09s\n",
      " it: 4250 | loss: 4.689 - 447.01s\n",
      "test loss: 5.005\n",
      "26 <unk>\n",
      " it: 4300 | loss: 4.603 - 463.15s\n",
      " it: 4350 | loss: 4.871 - 465.11s\n",
      " it: 4400 | loss: 4.690 - 467.18s\n",
      " it: 4450 | loss: 4.567 - 469.12s\n",
      " it: 4500 | loss: 4.835 - 471.21s\n",
      "test loss: 4.740\n",
      "873 take\n",
      " it: 4550 | loss: 4.902 - 487.51s\n",
      " it: 4600 | loss: 4.335 - 489.47s\n",
      " it: 4650 | loss: 4.477 - 491.38s\n",
      " it: 4700 | loss: 4.182 - 493.37s\n",
      " it: 4750 | loss: 4.640 - 495.06s\n",
      "test loss: 4.689\n",
      "26 <unk>\n",
      " it: 4800 | loss: 4.755 - 511.26s\n",
      " it: 4850 | loss: 4.514 - 513.14s\n",
      " it: 4900 | loss: 4.529 - 514.97s\n",
      " it: 4950 | loss: 4.769 - 516.92s\n",
      " it: 5000 | loss: 4.453 - 518.98s\n",
      "test loss: 4.576\n",
      " * model saved at 'models/dnn'\n",
      "26 <unk>\n",
      " it: 5050 | loss: 4.447 - 535.56s\n",
      " it: 5100 | loss: 4.449 - 537.38s\n",
      " it: 5150 | loss: 4.784 - 539.25s\n",
      " it: 5200 | loss: 4.520 - 541.22s\n",
      " it: 5250 | loss: 4.409 - 543.22s\n",
      "test loss: 4.488\n",
      "26 <unk>\n",
      " it: 5300 | loss: 4.272 - 559.27s\n",
      " it: 5350 | loss: 4.565 - 561.18s\n",
      " it: 5400 | loss: 4.372 - 563.20s\n",
      " it: 5450 | loss: 4.294 - 565.19s\n",
      " it: 5500 | loss: 4.482 - 567.38s\n",
      "test loss: 4.313\n",
      "873 take\n",
      " it: 5550 | loss: 4.591 - 583.64s\n",
      " it: 5600 | loss: 4.012 - 585.62s\n",
      " it: 5650 | loss: 4.102 - 587.48s\n",
      " it: 5700 | loss: 3.849 - 589.46s\n",
      " it: 5750 | loss: 4.244 - 591.13s\n",
      "test loss: 4.183\n",
      "26 <unk>\n",
      " it: 5800 | loss: 4.377 - 607.10s\n",
      " it: 5850 | loss: 4.056 - 608.96s\n",
      " it: 5900 | loss: 4.115 - 610.84s\n",
      " it: 5950 | loss: 4.429 - 612.84s\n",
      " it: 6000 | loss: 4.077 - 614.97s\n",
      "test loss: 4.084\n",
      " * model saved at 'models/dnn'\n",
      "26 <unk>\n",
      " it: 6050 | loss: 4.089 - 631.35s\n",
      " it: 6100 | loss: 4.141 - 633.19s\n",
      " it: 6150 | loss: 4.454 - 635.03s\n",
      " it: 6200 | loss: 4.238 - 636.96s\n",
      " it: 6250 | loss: 4.052 - 638.94s\n",
      "test loss: 3.976\n",
      "26 <unk>\n",
      " it: 6300 | loss: 3.988 - 654.92s\n",
      " it: 6350 | loss: 4.242 - 656.90s\n",
      " it: 6400 | loss: 4.068 - 658.98s\n",
      " it: 6450 | loss: 3.930 - 660.96s\n",
      " it: 6500 | loss: 4.167 - 663.09s\n",
      "test loss: 3.852\n",
      "873 take\n",
      " it: 6550 | loss: 4.258 - 679.29s\n",
      " it: 6600 | loss: 3.660 - 681.22s\n",
      " it: 6650 | loss: 3.788 - 683.07s\n",
      " it: 6700 | loss: 3.570 - 685.04s\n",
      " it: 6750 | loss: 3.887 - 686.66s\n",
      "test loss: 3.716\n",
      "26 <unk>\n",
      " it: 6800 | loss: 4.021 - 703.38s\n",
      " it: 6850 | loss: 3.652 - 705.39s\n",
      " it: 6900 | loss: 3.769 - 707.34s\n",
      " it: 6950 | loss: 4.039 - 709.40s\n",
      " it: 7000 | loss: 3.738 - 711.65s\n",
      "test loss: 3.670\n",
      " * model saved at 'models/dnn'\n",
      "26 <unk>\n",
      " it: 7050 | loss: 3.793 - 729.53s\n",
      " it: 7100 | loss: 3.802 - 731.42s\n",
      " it: 7150 | loss: 4.142 - 733.38s\n",
      " it: 7200 | loss: 3.938 - 735.41s\n",
      " it: 7250 | loss: 3.730 - 737.39s\n",
      "test loss: 3.537\n",
      "26 <unk>\n",
      " it: 7300 | loss: 3.635 - 755.00s\n",
      " it: 7350 | loss: 3.937 - 757.12s\n",
      " it: 7400 | loss: 3.693 - 759.41s\n",
      " it: 7450 | loss: 3.565 - 761.38s\n",
      " it: 7500 | loss: 3.860 - 763.60s\n",
      "test loss: 3.447\n",
      "873 take\n",
      " it: 7550 | loss: 3.902 - 780.98s\n",
      " it: 7600 | loss: 3.310 - 783.09s\n",
      " it: 7650 | loss: 3.454 - 785.08s\n",
      " it: 7700 | loss: 3.242 - 787.17s\n",
      " it: 7750 | loss: 3.543 - 788.94s\n",
      "test loss: 3.311\n",
      "26 <unk>\n",
      " it: 7800 | loss: 3.669 - 805.51s\n",
      " it: 7850 | loss: 3.362 - 807.43s\n",
      " it: 7900 | loss: 3.392 - 809.29s\n",
      " it: 7950 | loss: 3.699 - 811.33s\n",
      " it: 8000 | loss: 3.376 - 813.47s\n",
      "test loss: 3.293\n",
      " * model saved at 'models/dnn'\n",
      "1877 rise\n",
      " it: 8050 | loss: 3.543 - 829.85s\n",
      " it: 8100 | loss: 3.567 - 831.66s\n",
      " it: 8150 | loss: 3.853 - 833.50s\n",
      " it: 8200 | loss: 3.665 - 835.41s\n",
      " it: 8250 | loss: 3.435 - 837.27s\n",
      "test loss: 3.166\n",
      "26 <unk>\n",
      " it: 8300 | loss: 3.355 - 853.07s\n",
      " it: 8350 | loss: 3.627 - 855.01s\n",
      " it: 8400 | loss: 3.424 - 857.08s\n",
      " it: 8450 | loss: 3.241 - 858.95s\n",
      " it: 8500 | loss: 3.535 - 861.07s\n",
      "test loss: 3.112\n",
      "873 take\n",
      " it: 8550 | loss: 3.568 - 878.18s\n",
      " it: 8600 | loss: 3.014 - 880.29s\n",
      " it: 8650 | loss: 3.145 - 882.32s\n",
      " it: 8700 | loss: 2.997 - 884.46s\n",
      " it: 8750 | loss: 3.232 - 886.30s\n",
      "test loss: 3.009\n",
      "64 to\n",
      " it: 8800 | loss: 3.341 - 904.18s\n",
      " it: 8850 | loss: 3.073 - 906.20s\n",
      " it: 8900 | loss: 3.123 - 908.19s\n",
      " it: 8950 | loss: 3.377 - 910.33s\n",
      " it: 9000 | loss: 3.069 - 912.66s\n",
      "test loss: 3.023\n",
      " * model saved at 'models/dnn'\n",
      "898 against\n",
      " it: 9050 | loss: 3.281 - 930.87s\n",
      " it: 9100 | loss: 3.236 - 932.81s\n",
      " it: 9150 | loss: 3.591 - 934.81s\n",
      " it: 9200 | loss: 3.394 - 936.88s\n",
      " it: 9250 | loss: 3.140 - 938.97s\n",
      "test loss: 2.868\n",
      "26 <unk>\n",
      " it: 9300 | loss: 3.113 - 956.89s\n",
      " it: 9350 | loss: 3.361 - 958.92s\n",
      " it: 9400 | loss: 3.110 - 961.22s\n",
      " it: 9450 | loss: 2.985 - 963.33s\n",
      " it: 9500 | loss: 3.283 - 965.57s\n",
      "test loss: 2.819\n",
      "873 take\n",
      " it: 9550 | loss: 3.342 - 984.39s\n",
      " it: 9600 | loss: 2.812 - 986.61s\n",
      " it: 9650 | loss: 2.883 - 988.73s\n",
      " it: 9700 | loss: 2.766 - 991.03s\n",
      " it: 9750 | loss: 2.929 - 992.96s\n",
      "test loss: 2.728\n",
      "873 take\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it: 9800 | loss: 3.095 - 1013.64s\n",
      " it: 9850 | loss: 2.839 - 1016.11s\n",
      " it: 9900 | loss: 2.820 - 1018.55s\n",
      " it: 9950 | loss: 3.138 - 1021.16s\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from dnn_model import Model\n",
    "from data_loader import text_data\n",
    "data = text_data(\"./dataset/ptb/\")\n",
    "\n",
    "\n",
    "def initialize_session():\n",
    "    config = tf.ConfigProto()\n",
    "    #config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "##################################################\n",
    "BATCH_SIZE = 5         # 배치 사이즈\n",
    "num_k = 7               # 앞에 볼 단어 개수\n",
    "emb_dim = 64            # 단어 embedding dimension\n",
    "learning_rate = 0.0005  # Learning rate\n",
    "use_clip = True         # Gradient clipping 쓸지 여부\n",
    "##################################################\n",
    "\n",
    "model = Model(num_k=num_k, emb_dim=emb_dim, vocab_size=data.vocab_size,\n",
    "              use_clip=True, learning_rate=learning_rate)\n",
    "\n",
    "sess = initialize_session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "def sample_test(test_input=\"\"):\n",
    "    # test_input = raw_input(\"test text: \") # input(\"test text: \") for python 2, 3\n",
    "    test_x = np.zeros((1, num_k), dtype=np.int32)\n",
    "    words = test_input.split()\n",
    "    for i in range(min(num_k, len(words))):\n",
    "        test_x[0][-i-1] = data.w2idx[words[-i-1]]\n",
    "    out_x = sess.run(model.out_y, feed_dict={model.x: test_x})\n",
    "    print(out_x[0], data.idx2w[out_x[0]])\n",
    "\n",
    "def test_model():\n",
    "    num_it = int(len(data.test_ids) / BATCH_SIZE)\n",
    "    test_x = np.zeros((BATCH_SIZE, num_k), dtype=np.int32)\n",
    "    mask = np.zeros(BATCH_SIZE, dtype=np.int32)\n",
    "    test_loss, test_cnt = 0, 0\n",
    "\n",
    "    for _ in range(num_it):\n",
    "        test_ids, length = data.get_test(BATCH_SIZE)\n",
    "        max_len = max(length)\n",
    "\n",
    "        test_x.fill(0)\n",
    "        mask.fill(0)\n",
    "\n",
    "        for i in range(num_k - 1, max_len - 2):\n",
    "            for batch in range(len(test_ids)):\n",
    "                for j in range(0, num_k):\n",
    "                    if i < j or i - j >= length[batch]:\n",
    "                        break\n",
    "                    test_x[batch][num_k - j - 1] = test_ids[batch][i - j]\n",
    "                mask[batch] = 1 if length[batch] > i+1 else 0\n",
    "                if length[batch] > i + 1:\n",
    "                    input_y[batch] = test_ids[batch][i + 1]\n",
    "\n",
    "            loss = sess.run(model.loss, feed_dict={model.x: test_x, model.y: input_y, model.mask: mask})\n",
    "            test_loss += loss\n",
    "            test_cnt += 1\n",
    "    print(\"test loss: {:.3f}\".format(test_loss / test_cnt))\n",
    "\n",
    "\n",
    "input_x = np.zeros((BATCH_SIZE, num_k), dtype=np.int32)\n",
    "input_y = np.zeros(BATCH_SIZE, dtype=np.int32)\n",
    "input_mask = np.zeros(BATCH_SIZE, dtype=np.int32)\n",
    "length = np.zeros(BATCH_SIZE, dtype=np.int32)\n",
    "\n",
    "avg_loss, it_cnt = 0, 0\n",
    "it_log, it_test, it_save, it_sample = 50, 250, 1000, 250\n",
    "start_time = time.time()\n",
    "\n",
    "for it in range(0, 10000):\n",
    "    train_ids, length = data.get_train(BATCH_SIZE)\n",
    "    max_len = max(length)\n",
    "    input_x.fill(0)\n",
    "\n",
    "    for i in range(num_k-1, max_len-2):\n",
    "        for batch in range(len(train_ids)):\n",
    "            for j in range(0, num_k):\n",
    "                if i < j or i-j >= length[batch]:\n",
    "                    break\n",
    "                input_x[batch][num_k-j-1] = train_ids[batch][i-j]\n",
    "            input_mask[batch] = 1 if length[batch] > i+1 else 0\n",
    "\n",
    "            if length[batch] > i+1:\n",
    "                input_y[batch] = train_ids[batch][i+1]\n",
    "\n",
    "        loss, _ = sess.run([model.loss, model.update],\n",
    "                           feed_dict={model.x: input_x, model.y: input_y, model.mask: input_mask})\n",
    "        avg_loss += loss\n",
    "        it_cnt += 1\n",
    "\n",
    "    if it % it_log == 0:\n",
    "        print(\" it: {:4d} | loss: {:.3f} - {:.2f}s\".format(it, avg_loss / it_cnt, time.time() - start_time))\n",
    "        avg_loss, it_cnt = 0, 0\n",
    "\n",
    "    if it % it_test == 0:\n",
    "        test_model()\n",
    "    if it % it_save == 0 and it > 0:\n",
    "        model.save(sess)\n",
    "    if it % it_sample == 0 and it > 0:\n",
    "        sample_test(test_input=\"again the specialists were not able to\")\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
