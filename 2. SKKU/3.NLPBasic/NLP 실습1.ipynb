{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "#from baiye import BayesianFilter\n",
    "#bf = BayesianFilter()\n",
    "import math, sys\n",
    "from konlpy.tag import Twitter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFilter:\n",
    "    def __init__(self):\n",
    "        self.words = set() # 출현한 단어 기록\n",
    "        self.word_dict = {} # 카테고리마다의 출현 횟수 기록\n",
    "        self.category_dict = {} # 카테고리 출현 횟수 기록\n",
    "        self.cfd = _\n",
    "        \n",
    "    # 형태소 분석하기 --- (※1)\n",
    "    def split(self, text):\n",
    "        return text.split()\n",
    "        results = []\n",
    "        twitter = Twitter()\n",
    "        # 단어의 기본형 사용\n",
    "        malist = twitter.pos(text, norm=True, stem=True)\n",
    "        for word in malist:\n",
    "            # 어미/조사/구두점 등은 대상에서 제외 \n",
    "            if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "                results.append(word[0])\n",
    "        return results\n",
    "    \n",
    "    def fit_cfd(self, cfd):\n",
    "        \n",
    "        for category in cfd.conditions():\n",
    "            \n",
    "            for word in cfd[category]:\n",
    "                if not category in self.category_dict:\n",
    "                    self.category_dict[category] = 0\n",
    "                self.category_dict[category] += 1\n",
    "                \n",
    "                if not category in self.word_dict:\n",
    "                    self.word_dict[category] = {}\n",
    "                if not word in self.word_dict[category]:\n",
    "                    self.word_dict[category][word] = 0\n",
    "                self.word_dict[category][word] = cfd[category][word]\n",
    "                self.words.add(word)\n",
    "\n",
    "    def fit_list(self, data):\n",
    "        \n",
    "        training_data = []\n",
    "        \n",
    "        for c, w in data:\n",
    "            if not c in self.category_dict:\n",
    "                   self.category_dict[c] = 0\n",
    "                    \n",
    "            self.category_dict[c] += 1\n",
    "            self.words.add(w)\n",
    "            \n",
    "            training_data += {(c,w)}\n",
    "            \n",
    "        self.cfd = nltk.ConditionalFreqDist(training_data)\n",
    "        \n",
    "    # 단어 리스트에 점수 매기기--- (※4)\n",
    "    def score(self, words, category):\n",
    "        s_category = sum(self.category_dict.values())         \n",
    "        score = math.log( self.category_dict[category] / s_category )\n",
    "        for word in words:\n",
    "            #score += math.log(self.word_prob(word, category))\n",
    "            score += math.log( (self.cfd[category][word]+1) / (self.category_dict[category] + len(self.words)) )\n",
    "        return score\n",
    "    \n",
    "    # 예측하기 --- (※5)\n",
    "    def predict(self, text):\n",
    "        best_category = None\n",
    "        max_score = -sys.maxsize \n",
    "        words = self.split(text)\n",
    "        score_list = []\n",
    "        for category in self.category_dict.keys():\n",
    "            score = self.score(words, category)\n",
    "            score_list.append((category, score))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_category = category\n",
    "        return best_category, score_list\n",
    "\n",
    "    # 카테고리 내부의 단어 출현 비율 계산 --- (※6)\n",
    "    def word_prob(self, word, category):\n",
    "        n = self.get_word_count(word, category) + 1 # ---(※6a)\n",
    "        d = sum(self.word_dict[category].values()) + len(self.words)\n",
    "        return n / d\n",
    "\n",
    "def content_prep(text, stopwords):\n",
    "    #stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = []\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    for c,w in text:\n",
    "        #word = wnl.lemmatize(w)\n",
    "        word = w\n",
    "        #if(word!=w):\n",
    "        #    print(w,word)\n",
    "        if word.lower() not in stopwords and re.search('[A-Za-z0-9]$', word):\n",
    "        #if word.lower() not in stopwords:\n",
    "            content+={(c, word)}\n",
    "        #content = [w for w in word if w.lower() not in stopwords]\n",
    "    #for i in text:\n",
    "    #    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_word = [(genre,word) \n",
    "              for genre in ['romance','science_fiction','news']\n",
    "              for word in  brown.words(categories=genre)]\n",
    "              #for content_fraction(word,stopwords) in brown.words(categories=genre)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "myst_words = stopwords.words('english')\n",
    "#mylist = ['-',',','.','\"','\\'',';']\n",
    "#myst_words += mylist\n",
    "#myst_words\n",
    "fraction_genre_word = content_prep(genre_word,myst_words)\n",
    "#fraction_genre_word = genre_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = BayesianFilter()\n",
    "bf.fit_list(fraction_genre_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfd = nltk.ConditionalFreqDist(fraction_genre_word)\n",
    "#cfd['news']['The']\n",
    "#for category in cfd.conditions():\n",
    "#    for word in cfd[category]:\n",
    "#        print(word)\n",
    "#        print(cfd[category][word])\n",
    "#cfd['science_fiction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('romance', 'neither'),\n",
       " ('romance', 'liked'),\n",
       " ('romance', 'disliked'),\n",
       " ('romance', 'Old'),\n",
       " ('romance', 'Man'),\n",
       " ('romance', 'could'),\n",
       " ('romance', 'broken'),\n",
       " ('romance', 'bell'),\n",
       " ('romance', 'church'),\n",
       " ('romance', 'tower')]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bf = BayesianFilter()\n",
    "#bf.fit(cfd)\n",
    "#print(bf.word_dict)\n",
    "#print(bf.category_dict)\n",
    "fraction_genre_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.9 %\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "accuracy = 0.0\n",
    "t_count = 0\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "for c,w in fraction_genre_word:\n",
    "    pre, scorelist = bf.predict(w)\n",
    "    if(pre == c):\n",
    "        t_count += 1\n",
    "    #print('s word',w)\n",
    "    #print('s cate',c)\n",
    "    #print(\"결과 =\", pre)\n",
    "    #print(\"결과 =\", scorelist)\n",
    "    #print()\n",
    "    \n",
    "print(round(t_count/len(fraction_genre_word),3)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'little', 'yellow', 'dog', 'barked', 'at', 'the', 'Persian', 'cat']\n"
     ]
    }
   ],
   "source": [
    "tokens = \"The little yellow dog barked at the Persian cat\".split()\n",
    "print(tokens)\n",
    "tags_en = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('Persian', 'JJ'), ('cat', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(tags_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
